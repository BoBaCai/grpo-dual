# 串行生成多样性实验

## 目的

验证串行生成修复是否能解决"K个候选相同"的问题。

## 运行方法

```bash
cd /home/user/grpo-dual
python test_serial_generation.py
```

## 预期输出

脚本会对2个测试prompt各生成K=4个候选，并分析：

1. **唯一响应数**：K个候选中有多少个是不同的
2. **熵值**：每个候选的平均熵（前10 tokens）
3. **完整内容对比**：打印所有候选，方便人工对比

## 如何解读结果

### 情况A：候选完全相同（最坏）
```
唯一响应数: 1/4
⚠️ 所有候选完全相同！
熵统计: max=0.15
⚠️ 熵极低！模型输出高度确定
```

**结论：**
- 串行生成无效
- 模型太deterministic（top-1 prob太高）
- **下一步：**
  - 方案1：更激进采样（temperature=1.5, top_k=20）
  - 方案2：换Base model（去掉-Instruct）

---

### 情况B：候选部分相同（中等）
```
唯一响应数: 2/4
部分候选相同 (2个重复)
熵统计: max=0.8
⚠️ 熵偏低，可能需要更激进的采样
```

**结论：**
- 串行生成部分有效
- 但多样性仍不足
- **下一步：**
  - 增大temperature到1.2
  - 或减小top_k到20

---

### 情况C：候选都不同（最好）
```
唯一响应数: 4/4
✓ 所有候选都不同
熵统计: max=2.1
✓ 熵正常
```

**结论：**
- 串行生成有效！
- 可以继续完整训练
- **下一步：**
  - 运行完整训练，观察reward std是否>0
  - 观察C2监控的零梯度组比例

---

## 快速测试更激进采样

如果情况A或B，可以直接修改脚本测试：

```python
# 在test_serial_generation.py中修改：
TEMPERATURE = 1.5  # 从0.9改到1.5
TOP_K = 20         # 从100改到20
```

然后重新运行看结果是否改善。

## 预期运行时间

- GPU: ~2-3分钟
- CPU: ~10-15分钟

## 依赖

如果缺少依赖，运行：
```bash
pip install torch transformers
```
