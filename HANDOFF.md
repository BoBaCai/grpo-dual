# GRPO Multi-Objective Training - Handoff Document

**Last Updated:** 2025-11-08
**Current Branch:** `claude/open-trainer-py-011CUp9RqkPbRBQPMVzBRuJ3`
**Status:** A+Bä¿®å¤å·²å®Œæˆï¼Œç­‰å¾…è®­ç»ƒéªŒè¯

---

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ç›®æ ‡
ä½¿ç”¨ GRPO (Group Relative Policy Optimization) å¯¹ Llama-3-8B-Instruct è¿›è¡Œå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼š
- **Fairness (BBQæ•°æ®é›†)**: å‡å°‘åè§ï¼Œå…¬å¹³å›ç­”é—®é¢˜
- **Hallucination (HaluEvalæ•°æ®é›†)**: å‡å°‘å¹»è§‰ï¼ŒåŸºäºè¯æ®å›ç­”

### æŠ€æœ¯æ ˆ
- Base Model: `meta-llama/Meta-Llama-3-8B-Instruct`
- Method: GRPO + LoRA + Branched KL Control
- Framework: PyTorch + Transformers + PEFT

---

## ğŸ”¥ å…³é”®é—®é¢˜å†å²

### é—®é¢˜1ï¼šç†µå¡Œé™·ï¼ˆEntropy Collapseï¼‰
**ç—‡çŠ¶ï¼š**
- æ¨¡å‹è¾“å‡ºé«˜åº¦ç¡®å®šæ€§ï¼ˆmax prob â‰ˆ 0.99999ï¼‰
- ç†µå€¼æä½ï¼ˆ0.2-0.7ï¼Œæ­£å¸¸åº” >1.5ï¼‰
- æ‰€æœ‰ç”Ÿæˆéƒ½æ˜¯ç›¸åŒæ¨¡æ¿ï¼š"The context does not provide sufficient information..."
- åŒä¸€promptçš„Kä¸ªå€™é€‰å‡ ä¹ç›¸åŒ â†’ advantage=0 â†’ æ— æ¢¯åº¦ä¿¡å·

**æ ¹æœ¬åŸå› ï¼š**
1. `MIN_NEW_TOKENS_TRAIN=30` å¼ºåˆ¶æ‰€æœ‰å›ç­”â‰¥30 tokens
2. Judgeå¯¹"å®‰å…¨åºŸè¯æ¨¡æ¿"ç»™æ­£åˆ†
3. å¯¼è‡´æ¨¡å‹æ”¶æ•›åˆ°å•ä¸€æ¨¡æ¿è¾“å‡º

**ä¿®å¤æ–¹æ¡ˆï¼ˆA+Bï¼Œå·²å®Œæˆï¼‰ï¼š**
- âœ… A: `MIN_NEW_TOKENS_TRAIN: 30 â†’ 5` (trainer.py:226)
- âœ… B: æ¨¡æ¿æ£€æµ‹å™¨ï¼Œæƒ©ç½šé€ƒé¿å›ç­” (trainer.py:1594-1621)

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 226: MIN_NEW_TOKENS_TRAIN = 5
  - Line 1586-1621: MultiCloudJudge.evaluate() ä¸­çš„æ¨¡æ¿æ£€æµ‹å™¨
```

---

### é—®é¢˜2ï¼šæ•°æ®é›†ä½¿ç”¨é—®é¢˜ï¼ˆPiä¸“å®¶åˆ†æï¼‰

#### BBQæ•°æ®é›†ï¼ˆå·²æ­£ç¡®å¤„ç† âœ…ï¼‰
**å…³é”®ç‚¹ï¼š**
- Unknowné€‰é¡¹ä½ç½®æ˜¯åŠ¨æ€çš„ï¼ˆä¸å›ºå®šåœ¨A/B/CæŸä¸ªä½ç½®ï¼‰
- å¿…é¡»é€šè¿‡ `answer_info[*][1]=="unknown"` åˆ¤å®š
- Ambiguousæ ·æœ¬ï¼šå¿…é¡»é€‰Unknown
- Disambiguatedæ ·æœ¬ï¼šæœ‰æ˜ç¡®æ­£ç¡®ç­”æ¡ˆ

**ä»£ç éªŒè¯ï¼š**
```python
# Line 1126-1133: _find_unknown_option æ­£ç¡®ä½¿ç”¨answer_info
if val[1]=="unknown":
    return chr(65+idx)  # åŠ¨æ€ç¡®å®šA/B/C
```
âœ… å·²æ­£ç¡®å®ç°

#### HaluEvalæ•°æ®é›†ï¼ˆéƒ¨åˆ†é—®é¢˜ âš ï¸ï¼‰

**é—®é¢˜2.1: Generalå­é›†å™ªå£°ä¸¥é‡**
- "å¹»è§‰"æ¦‚å¿µæ··ç”¨ï¼šäº‹å®é”™è¯¯ã€ä¸å®Œæ•´å›ç­”ã€èƒ½åŠ›å£°æ˜ã€æ ¼å¼é—®é¢˜å…¨æ··åœ¨ä¸€èµ·
- 815ä¸ªyesæ ‡æ³¨ä¸­ï¼Œçº¦13ä¸ªhallucination_spansä¸ºç©º
- çº¦200+ä¸ªæ¶‰åŠ"As an AI language model..."è¢«æ ‡ä¸ºå¹»è§‰
- **å½±å“ï¼š** rewardä¿¡å·äº’ç›¸çŸ›ç›¾ï¼Œæ¨¡å‹å€¾å‘ä¿å®ˆæ¨¡æ¿

**é—®é¢˜2.2: é…å¯¹æ ·æœ¬æœªå……åˆ†åˆ©ç”¨**
- qa/dialogueå­é›†æœ‰ `right_answer` å’Œ `hallucinated_answer`
- å½“å‰åªç”¨äº† `right_answer` åšSFT/target
- æœªåšå¯¹æ¯”å­¦ä¹ ï¼ˆpositive vs negativeï¼‰
- **å½±å“ï¼š** æ¨¡å‹åªçŸ¥é“"æ­£ç¡®"ï¼Œä¸çŸ¥é“"å¹»è§‰"é•¿ä»€ä¹ˆæ ·

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 1163-1276: HaluEvalAdapter.load_samples()
  - Line 1220: åªç”¨right_answerï¼ˆå¾…æ”¹è¿›ï¼‰
  - Line 1234: åªç”¨right_responseï¼ˆå¾…æ”¹è¿›ï¼‰
  - Line 1255-1274: generalå­é›†å¤„ç†ï¼ˆå¯èƒ½éœ€è¦è¿‡æ»¤ï¼‰
```

---

## âœ… å·²å®Œæˆçš„ä¿®å¤

### Commit: f140a1c "Fix entropy collapse: reduce MIN_NEW_TOKENS and penalize template responses"

**ä¿®æ”¹1: æ”¾æ¾è§£ç ç­–ç•¥**
```python
# trainer.py:226
MIN_NEW_TOKENS_TRAIN = 5  # ä»30é™åˆ°5
```
**æ•ˆæœï¼š** å…è®¸çŸ­å›ç­”ï¼ŒåŒä¸€promptçš„Kä¸ªå€™é€‰äº§ç”Ÿå·®å¼‚ â†’ æ¢å¤æ¢¯åº¦ä¿¡å·

**ä¿®æ”¹2: æ¨¡æ¿æ£€æµ‹å™¨**
```python
# trainer.py:1594-1621
# æ£€æµ‹6ç§æ¨¡æ¿çŸ­è¯­ï¼š
template_phrases = [
    "does not provide sufficient information",
    "cannot be determined",
    "not enough information",
    "insufficient information",
    "unable to determine",
    "context does not"
]

# åˆ†å±‚æƒ©ç½šï¼š
- BBQ disambiguated: -0.7ï¼ˆæœ‰æ˜ç¡®ç­”æ¡ˆå´é€ƒé¿ï¼‰
- HaluEval qa/dialogue/summarization: -0.5ï¼ˆæœ‰knowledgeå´é€ƒé¿ï¼‰
- Ambiguous/general: 0.0ï¼ˆå‹‰å¼ºå¯ä»¥ï¼Œä½†ä¸ç»™æ­£åˆ†ï¼‰
```
**æ•ˆæœï¼š** æ¨¡æ¿ä¸å†æ˜¯"å®‰å…¨æœ€ä¼˜ç­–ç•¥"

---

## ğŸ“Š å½“å‰è®­ç»ƒçŠ¶æ€

### é…ç½® (trainer.py:126-286)
```python
# åŸºç¡€
BASE_MODEL = "meta-llama/Meta-Llama-3-8B-Instruct"
GRPO_STEPS = 500
GRPO_BATCH_SIZE = 2
K_ROLLOUTS = 4  # æ¯ä¸ªpromptç”Ÿæˆ4ä¸ªå€™é€‰
GRADIENT_ACCUMULATION_STEPS = 2

# ç”Ÿæˆé…ç½®ï¼ˆå·²ä¿®å¤ï¼‰
MAX_NEW_TOKENS_TRAIN = 128
MIN_NEW_TOKENS_TRAIN = 5  # âš¡ å·²ä¿®å¤
TEMPERATURE_TRAIN = 0.9
TOP_K_TRAIN = 100
TOP_P_TRAIN = 0.9
REP_PENALTY_TRAIN = 1.18

# æ•°æ®
N_BBQ_TRAIN = 1100
N_HALU_TRAIN = 400

# Reward Scaleï¼ˆå¤šç›®æ ‡å¹³è¡¡ï¼‰
FAIRNESS_REWARD_SCALE = 0.7
HALLUCINATION_REWARD_SCALE = 1.0

# KLæ§åˆ¶ï¼ˆåˆ†æ”¯åŒ–ï¼‰
beta_f_init = 0.30  # Fairness
beta_h_init = 0.30  # Hallucination
```

### å¾…è§‚å¯ŸæŒ‡æ ‡ï¼ˆå‰50æ­¥æœ€å…³é”®ï¼‰

#### ğŸ”¥ ä¼˜å…ˆçº§1ï¼šç†µæ˜¯å¦æ¢å¤ï¼ˆå‰5æ­¥ï¼‰
```
[Fairnessè¯Šæ–­@stepX]
  Entropy: X.XXX
```
**æœŸæœ›ï¼š** >1.0ï¼ˆç†æƒ³>1.5ï¼‰
**å¦‚æœï¼š** ä»<0.5 â†’ A+Bä¿®å¤å¤±è´¥

#### ğŸ”¥ ä¼˜å…ˆçº§2ï¼šæ¢¯åº¦ä¿¡å·ï¼ˆå‰10æ­¥ï¼‰
```
Rewardç»Ÿè®¡:
  Fairness: std=X.XXX
  Hallucination: std=X.XXX

æ¢¯åº¦ä¿¡å·å¼ºåº¦:
  Fairness signal: X.XXXX
  Hallucination signal: X.XXXX
```
**æœŸæœ›ï¼š** std>0.1, signal>0
**å¦‚æœï¼š** å¤§é‡std=0 â†’ ä»æœ‰æ¨¡å¼åå¡Œ

#### â­ ä¼˜å…ˆçº§3ï¼šæ¨¡æ¿æ£€æµ‹å™¨æ˜¯å¦ç”Ÿæ•ˆï¼ˆå‰20æ­¥ï¼‰
```
[Judge@stepX] providers={'template_detector': X, ...}
```
**æœŸæœ›ï¼š** å‰5æ­¥æœ‰ä¸€å®šæ¯”ä¾‹ï¼Œ5-20æ­¥é€æ­¥å‡å°‘
**å¦‚æœï¼š** æŒç»­>50% â†’ ç­–ç•¥ä»é”åœ¨æ¨¡æ¿

#### â­ ä¼˜å…ˆçº§4ï¼šç”Ÿæˆå¤šæ ·æ€§
**æœŸæœ›ï¼š** ä¸å†å…¨æ˜¯"insufficient information"ï¼Œæœ‰åŸºäºcontextçš„å®è´¨å›ç­”

---

## ğŸ› ï¸ å¾…ä¿®å¤é—®é¢˜ï¼ˆæ ¹æ®è®­ç»ƒç»“æœå†³å®šä¼˜å…ˆçº§ï¼‰

### Plan B1: è¿‡æ»¤HaluEval-generalå™ªå£°ï¼ˆå¦‚æœHallucinationä¿¡å·ä»å¼±ï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1255-1274

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
if sub == "general":
    filtered = []
    for it in data:
        if it.get("hallucination") == "no":
            filtered.append(it)
        elif it.get("hallucination") == "yes":
            spans = it.get("hallucination_spans", [])
            # åªä¿ç•™æ˜ç¡®äº‹å®é”™è¯¯ï¼Œæ’é™¤ä¸å®Œæ•´/èƒ½åŠ›å£°æ˜/æ ¼å¼é—®é¢˜
            if spans and not any(keyword in str(spans).lower()
                                 for keyword in ["incomplete", "cannot", "ai language model", "format"]):
                filtered.append(it)
    data = filtered
```

### Plan B2: å¯ç”¨HaluEvalé…å¯¹å¯¹æ¯”å­¦ä¹ ï¼ˆæå‡æ•ˆæœï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1220, 1234

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
# qaå­é›†ï¼šç”Ÿæˆpositiveå’Œnegativeä¸¤ä¸ªæ ·æœ¬
# Positive
out.append(Sample(
    id=f"halu_{sub}_{i}_pos",
    task="hallucination",
    prompt=prompt,
    target=build_target(it['right_answer']),
    meta={**meta, "label": "positive"}
))

# Negative
out.append(Sample(
    id=f"halu_{sub}_{i}_neg",
    task="hallucination",
    prompt=prompt,
    target=build_target(it['hallucinated_answer']),
    meta={**meta, "label": "negative"}
))

# Judgeéœ€è¦ç›¸åº”è°ƒæ•´ï¼Œå¯¹negativeæ ·æœ¬ç»™è´Ÿåˆ†
```

### Plan B3: é™ä½Generalæƒé‡ï¼ˆå¿«é€Ÿæ–¹æ¡ˆï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1164

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
# åŠ æƒé‡‡æ ·ï¼Œé™ä½generalå­é›†æƒé‡
per_weights = {
    "qa": 1.5,
    "dialogue": 1.5,
    "general": 0.5,  # é™ä½æƒé‡
    "summarization": 1.0
}
per = max(1, int(n_total * per_weights[sub] / sum(per_weights.values())))
```

### Plan B4: æ£€æŸ¥Tokenizationæˆªæ–­é—®é¢˜ï¼ˆå¦‚æœä¸¤ä¸ªä»»åŠ¡éƒ½ä»å¼±ï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:2087, 2256, 2501, 2506, 2532

**æ½œåœ¨é—®é¢˜ï¼š**
- å¤šå¤„ä½¿ç”¨ `truncation=True, max_length=896`
- BBQ contextå¯èƒ½è¢«æˆªæ–­ï¼Œå¯¼è‡´disambiguatedæ ·æœ¬çœ‹èµ·æ¥åƒambiguous
- SFTæ—¶å¯èƒ½æŠŠtargetæˆªæ‰

**éªŒè¯è„šæœ¬ï¼š**
```python
# æ£€æŸ¥BBQæ ·æœ¬tokenizationåçš„é•¿åº¦
for sample in bbq[:100]:
    formatted = apply_chat_template(tokenizer, sample.prompt, system_msg)
    tokens = tokenizer(formatted, truncation=False)
    if len(tokens['input_ids']) > 700:
        print(f"âš ï¸ Sample {sample.id}: {len(tokens['input_ids'])} tokens (å¯èƒ½è¢«æˆªæ–­)")
        print(f"Context condition: {sample.meta.get('context_condition')}")
```

---

## ğŸ¯ å†³ç­–æ ‘ï¼ˆ20æ­¥åï¼‰

```
è®­ç»ƒ20æ­¥åè§‚å¯Ÿç»“æœ
â”‚
â”œâ”€ Fairnessæ¢å¤ + Hallucinationæ¢å¤
â”‚  â””â”€> âœ… A+BæˆåŠŸï¼Œç»§ç»­è®­ç»ƒåˆ°100-200æ­¥
â”‚
â”œâ”€ Fairnessæ¢å¤ + Hallucinationä»å¼±
â”‚  â””â”€> âš¡ Generalå™ªå£°ä¸»å¯¼
â”‚     â””â”€> å®æ–½Plan B1ï¼ˆè¿‡æ»¤generalï¼‰æˆ–B3ï¼ˆé™ä½æƒé‡ï¼‰
â”‚
â”œâ”€ Fairnessä»å¼± + Hallucinationä»å¼±
â”‚  â””â”€> ğŸ” å…¶ä»–é—®é¢˜
â”‚     â””â”€> å®æ–½Plan B4ï¼ˆæ£€æŸ¥æˆªæ–­ï¼‰
â”‚     â””â”€> æ£€æŸ¥ambig/disambigé‡‡æ ·æ¯”ä¾‹
â”‚
â””â”€ Fairnessä»å¼± + Hallucinationæ¢å¤
   â””â”€> ğŸ¤” ä¸å¤ªå¯èƒ½ï¼Œæ·±å…¥è¯Šæ–­BBQ
```

---

## ğŸ“ å…³é”®æ–‡ä»¶ä½ç½®

### ä¸»è®­ç»ƒè„šæœ¬
```
grpo-dual/src/grpo/trainer.py (3509è¡Œ)
  - Line 126-286: Configé…ç½®
  - Line 226: MIN_NEW_TOKENS_TRAIN (âš¡å·²ä¿®å¤)
  - Line 970-1009: read_json_flex (JSONLè¯»å–)
  - Line 1031-1157: BBQAdapter
  - Line 1126-1133: _find_unknown_option (âœ…æ­£ç¡®å®ç°)
  - Line 1158-1276: HaluEvalAdapter (âš ï¸å¾…ä¼˜åŒ–)
  - Line 1369-1646: MultiCloudJudge
  - Line 1586-1621: evaluate() + æ¨¡æ¿æ£€æµ‹å™¨ (âš¡å·²æ·»åŠ )
  - Line 2681-3220: grpo_train (ä¸»è®­ç»ƒå¾ªç¯)
```

### æ•°æ®æ–‡ä»¶
```
/workspace/data/bbq/
  - Gender_identity.jsonl (5672æ¡ï¼ŒJSONLæ ¼å¼)
  - Disability_status.jsonl (1556æ¡ï¼ŒJSONLæ ¼å¼)
  - ... (å…¶ä»–9ä¸ªç±»åˆ«)

/workspace/data/halueval/
  - qa_data.json (10000æ¡ï¼ŒJSONLæ ¼å¼ï¼Œæœ‰é…å¯¹)
  - dialogue_data.json (10000æ¡ï¼ŒJSONLæ ¼å¼ï¼Œæœ‰é…å¯¹)
  - general_data.json (4507æ¡ï¼ŒJSONLæ ¼å¼ï¼Œâš ï¸å™ªå£°ä¸¥é‡)
  - summarization_data.json (JSONLæ ¼å¼)
```

### è¾“å‡ºæ–‡ä»¶
```
/workspace/multiobjective_llama/<RUN_ID>/
  - train_step_metrics.csv (é€æ­¥æŒ‡æ ‡)
  - train_step_metrics.jsonl (å¤‡ç”¨)
  - training_metrics_summary.json (æœ€ç»ˆæ±‡æ€»)
```

---

## ğŸ”¬ è¯Šæ–­æ–¹æ³•

### å¿«é€Ÿæ£€æŸ¥æ¸…å•ï¼ˆè®­ç»ƒå‰ï¼‰
```bash
# 1. ç¡®è®¤é…ç½®å·²æ›´æ–°
grep "MIN_NEW_TOKENS_TRAIN = 5" grpo-dual/src/grpo/trainer.py
grep "template_phrases = \[" grpo-dual/src/grpo/trainer.py

# 2. æ£€æŸ¥gitçŠ¶æ€
git log -1 --oneline
# åº”è¯¥çœ‹åˆ°: f140a1c Fix entropy collapse...

# 3. ç¡®è®¤åœ¨æ­£ç¡®åˆ†æ”¯
git branch --show-current
# åº”è¯¥æ˜¯: claude/open-trainer-py-011CUp9RqkPbRBQPMVzBRuJ3
```

### è®­ç»ƒä¸­è§‚å¯Ÿï¼ˆå‰20æ­¥ï¼‰
å…³æ³¨ç»ˆç«¯è¾“å‡ºä¸­çš„ï¼š
1. **Fairnessè¯Šæ–­æ¨¡å—** - ç†µå€¼ã€ç”Ÿæˆé•¿åº¦ã€ç”Ÿæˆå†…å®¹
2. **Reward Scaleè¯Šæ–­** - ä¿¡å·å¼ºåº¦ã€stdã€EMAæ¯”å€¼
3. **Judge provideråˆ†å¸ƒ** - template_detectorå‡ºç°é¢‘ç‡
4. **é•¿åº¦æƒ©ç½šç»Ÿè®¡** - å¤šå°‘æ ·æœ¬è¢«æƒ©ç½š

### è®­ç»ƒååˆ†æï¼ˆ50æ­¥+ï¼‰
```bash
# æŸ¥çœ‹CSVï¼ˆæ¨èç”¨pandasï¼‰
import pandas as pd
df = pd.read_csv("/workspace/multiobjective_llama/<RUN_ID>/train_step_metrics.csv")

# å…³é”®åˆ—
df[['step', 'kl_f', 'kl_h', 'reward_f_mean', 'reward_h_mean',
    'clip_frac', 'gen_len_f_mean', 'gen_len_h_mean',
    'trunc_frac_f', 'trunc_frac_h']].head(20)

# ç»˜åˆ¶è¶‹åŠ¿
import matplotlib.pyplot as plt
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
df.plot(x='step', y='reward_f_mean', ax=axes[0,0], title='Fairness Reward')
df.plot(x='step', y='reward_h_mean', ax=axes[0,1], title='Hallucination Reward')
df.plot(x='step', y='gen_len_f_mean', ax=axes[1,0], title='Fairness Length')
df.plot(x='step', y='gen_len_h_mean', ax=axes[1,1], title='Hallucination Length')
plt.tight_layout()
plt.savefig('training_trends.png')
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### Piä¸“å®¶çš„åˆ†æè¦ç‚¹

#### BBQæ•°æ®é›†ï¼ˆå·²éªŒè¯æ— é—®é¢˜ï¼‰
- âœ… ç»“æ„è‰¯å¥½ï¼Œæ ‡æ³¨ä¸€è‡´
- âœ… Ambiguous/Disambiguatedè®¾è®¡æ­£ç¡®
- âœ… æ ‡ç­¾åˆ†å¸ƒå‡è¡¡ï¼ˆå„é€‰é¡¹ã€å„ææ€§éƒ½æˆå¯¹å‡ºç°ï¼‰
- âš ï¸ Unknowné€‰é¡¹ä½ç½®æ˜¯åŠ¨æ€çš„ï¼ˆå¿…é¡»ç”¨answer_infoåˆ¤å®šï¼‰

#### HaluEvalæ•°æ®é›†
**Generalå­é›†é—®é¢˜ï¼š**
- "å¹»è§‰"æ¦‚å¿µæ··ç”¨ï¼ˆäº‹å®é”™è¯¯+ä¸å®Œæ•´+èƒ½åŠ›å£°æ˜+æ ¼å¼é—®é¢˜ï¼‰
- çº¦815ä¸ªyesæ ‡æ³¨ï¼Œå…¶ä¸­13ä¸ªspansä¸ºç©º
- çº¦200+ä¸ª"As an AI..."è¢«æ ‡ä¸ºå¹»è§‰
- ç»“è®ºï¼šéœ€è¦è¿‡æ»¤ï¼Œåªä¿ç•™æ˜ç¡®äº‹å®é”™è¯¯

**Dialogueå­é›†ï¼ˆè´¨é‡å¥½ï¼‰ï¼š**
- âœ… æˆå¯¹æ ‡æ³¨ï¼ˆright vs hallucinatedï¼‰
- âœ… åŸºäºknowledgeçš„ä¸€è‡´æ€§
- âœ… åªæœ‰è½»å¾®å™ªå£°

**QAå­é›†ï¼ˆè´¨é‡å¥½ï¼‰ï¼š**
- âœ… æˆå¯¹æ ‡æ³¨
- âœ… æ¸…æ™°çš„äº‹å®ä¾æ®

### ç®—æ³•å‚è€ƒ

#### BAPO (Balanced Advantage Policy Optimization)
- åŠ¨æ€è°ƒæ•´PPOè£å‰ªè¾¹ç•Œï¼ˆä¸å¯¹ç§°ï¼‰
- c_low: 0.6â†’0.9, c_high: 1.2â†’3.0
- ç›®æ ‡ï¼šå¹³è¡¡positive/negativeæ ·æœ¬çš„æ¢¯åº¦è´¡çŒ®
- é€‚ç”¨åœºæ™¯ï¼šé˜²æ­¢ç†µå¡Œé™·ï¼Œé¼“åŠ±æ¢ç´¢

#### DAPO (Decoupled Clip and Dynamic Sampling Policy Optimization)
- Clip-Higher: ä¸Šç•Œä»1.2â†’1.28
- Dynamic Sampling: è¿‡æ»¤accuracy=1æˆ–0çš„promptç»„
- Token-Level Loss: å¯¹æ‰€æœ‰tokenèšåˆ
- Overlong Reward Shaping: æƒ©ç½šè¶…é•¿å›ç­”

---

## ğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’

### çŸ­æœŸï¼ˆä»Šå¤©ï¼‰
1. âœ… ç”¨A+Bä¿®å¤çš„ä»£ç è·‘50æ­¥
2. âœ… è§‚å¯Ÿå‰20æ­¥è¯Šæ–­è¾“å‡º
3. âœ… æ ¹æ®ç»“æœå†³å®šæ˜¯å¦éœ€è¦Plan B

### ä¸­æœŸï¼ˆå¦‚æœA+BæˆåŠŸï¼‰
1. ç»§ç»­è®­ç»ƒåˆ°100-200æ­¥
2. è§‚å¯Ÿæ”¶æ•›æƒ…å†µ
3. è¯„ä¼°Paretoå‰æ²¿

### ä¸­æœŸï¼ˆå¦‚æœéœ€è¦Plan Bï¼‰
1. æ ¹æ®å†³ç­–æ ‘é€‰æ‹©å¯¹åº”æ–¹æ¡ˆ
2. å®æ–½ä¿®å¤
3. é‡æ–°è®­ç»ƒ50æ­¥éªŒè¯

### é•¿æœŸï¼ˆä¼˜åŒ–æ–¹å‘ï¼‰
1. å®æ–½HaluEvalé…å¯¹å¯¹æ¯”å­¦ä¹ ï¼ˆPlan B2ï¼‰
2. è€ƒè™‘BAPO/DAPOæŠ€æœ¯ï¼ˆä¸å¯¹ç§°è£å‰ªã€åŠ¨æ€é‡‡æ ·ï¼‰
3. å¢åŠ Best-of-Næˆ–Rejection Sampling

---

## âš ï¸ å·²çŸ¥é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

### ç¯å¢ƒ
- GPUæ˜¾å­˜é™åˆ¶ï¼šå·²é™ä½batch sizeå’ŒLoRA rank
- APIé…é¢ï¼šOpenAI + ClaudeåŒäº‘ï¼Œæœ‰heuristicå…œåº•
- ç½‘ç»œç¨³å®šæ€§ï¼šå·²å®ç°é‡è¯•å’ŒæŒ‡æ•°é€€é¿

### æ•°æ®
- BBQåªç”¨äº†2ä¸ªç±»åˆ«ï¼ˆGender, Disabilityï¼‰ï¼Œè¿˜æœ‰9ä¸ªç±»åˆ«æœªç”¨
- HaluEvalçš„generalå­é›†å™ªå£°éœ€è¦å¤„ç†
- é…å¯¹æ ·æœ¬æœªå……åˆ†åˆ©ç”¨

### è®­ç»ƒ
- SFT targetå¯èƒ½ä¸RLé˜¶æ®µçš„æ¨¡æ¿æ£€æµ‹å™¨æœ‰è½»å¾®å†²çªï¼ˆambiguousæ ·æœ¬ï¼‰
- Tokenizationå¯èƒ½æˆªæ–­é•¿contextï¼ˆå¾…éªŒè¯ï¼‰
- KLæ§åˆ¶çš„Î²å€¼å¯èƒ½éœ€è¦æ ¹æ®è®­ç»ƒè¿›åº¦è°ƒæ•´

---

## ğŸ“ äº¤æ¥æ£€æŸ¥ç‚¹

æ¥æ‰‹æ­¤é¡¹ç›®çš„äººåº”è¯¥èƒ½å¤Ÿï¼š

### å¿…éœ€äº†è§£
1. âœ… ç†µå¡Œé™·é—®é¢˜çš„æ ¹æœ¬åŸå› å’Œä¿®å¤æ–¹æ¡ˆ
2. âœ… BBQæ•°æ®é›†çš„æ­£ç¡®ä½¿ç”¨æ–¹å¼ï¼ˆåŠ¨æ€unknownï¼‰
3. âœ… HaluEvalæ•°æ®é›†çš„é—®é¢˜å’Œæ½œåœ¨ä¿®å¤æ–¹æ¡ˆ
4. âœ… å¦‚ä½•è§£è¯»è®­ç»ƒæ—¥å¿—ï¼ˆç†µã€æ¢¯åº¦ä¿¡å·ã€provideråˆ†å¸ƒï¼‰

### å¿…éœ€æŒæ¡
1. âœ… è¿è¡Œè®­ç»ƒå¹¶è§‚å¯Ÿå‰20æ­¥
2. âœ… æ ¹æ®å†³ç­–æ ‘é€‰æ‹©å¯¹åº”çš„Plan B
3. âœ… ä¿®æ”¹ä»£ç å®æ–½Plan Bï¼ˆå¦‚æœéœ€è¦ï¼‰
4. âœ… åˆ†æCSVæ–‡ä»¶å’Œç»˜åˆ¶è¶‹åŠ¿å›¾

### å¯é€‰æŠ€èƒ½
1. BAPO/DAPOç®—æ³•çš„å®ç°
2. Paretoå‰æ²¿ä¼˜åŒ–
3. æ›´å¤æ‚çš„reward shaping

---

## ğŸ“ æ›´æ–°æ—¥å¿—

**2025-11-08:**
- âœ… å®ŒæˆA+Bä¿®å¤ï¼ˆMIN_NEW_TOKENSé™ä½ + æ¨¡æ¿æ£€æµ‹å™¨ï¼‰
- âœ… Commit f140a1cæ¨é€åˆ°è¿œç¨‹åˆ†æ”¯
- âœ… æ•´ç†Piä¸“å®¶çš„æ•°æ®é›†åˆ†æ
- âœ… å‡†å¤‡Plan Bæ–¹æ¡ˆï¼ˆå¾…è®­ç»ƒç»“æœå†³å®šï¼‰
- ğŸ“‹ åˆ›å»ºæœ¬äº¤æ¥æ–‡æ¡£

**å¾…æ›´æ–°ï¼ˆè®­ç»ƒå®Œæˆåï¼‰ï¼š**
- [ ] å‰20æ­¥çš„å®é™…è§‚å¯Ÿç»“æœ
- [ ] æ˜¯å¦éœ€è¦å®æ–½Plan Bï¼ˆå“ªä¸ªï¼‰
- [ ] æœ€ç»ˆè®­ç»ƒæ•ˆæœå’Œæ”¶æ•›æƒ…å†µ

---

**æ–‡æ¡£ç»“æŸã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒtrainer.pyä¸­çš„è¯¦ç»†æ³¨é‡Šæˆ–é‡æ–°é˜…è¯»æœ¬æ–‡æ¡£çš„ç›¸å…³ç« èŠ‚ã€‚**
