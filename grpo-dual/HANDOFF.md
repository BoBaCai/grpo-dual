# GRPO Multi-Objective Training - Handoff Document

**Last Updated:** 2025-11-08
**Current Branch:** `claude/open-trainer-py-011CUp9RqkPbRBQPMVzBRuJ3`
**Status:** å…³é”®å·¥ç¨‹é—®é¢˜ä¿®å¤å®Œæˆï¼ˆä¸²è¡Œç”Ÿæˆ + Advantageè®¡ç®— + ç†µå¥–åŠ± + KLçº¦æŸ + æ¨¡æ¿æ£€æµ‹å¢å¼ºï¼‰

---

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ç›®æ ‡
ä½¿ç”¨ GRPO (Group Relative Policy Optimization) å¯¹ Llama-3-8B è¿›è¡Œå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼š
- **Fairness (BBQæ•°æ®é›†)**: å‡å°‘åè§ï¼Œå…¬å¹³å›ç­”é—®é¢˜
- **Hallucination (HaluEvalæ•°æ®é›†)**: å‡å°‘å¹»è§‰ï¼ŒåŸºäºè¯æ®å›ç­”

### æŠ€æœ¯æ ˆ
- Base Model: `meta-llama/Meta-Llama-3-8B-Instruct` **ã€å®éªŒåå›åˆ°Instructã€‘Base modelæ— æ³•ç†è§£æ ¼å¼**
- Method: GRPO + LoRA + Branched KL Control
- Framework: PyTorch + Transformers + PEFT

---

## ğŸ”¥ å…³é”®é—®é¢˜å†å²

### é—®é¢˜1ï¼šç†µå¡Œé™·ï¼ˆEntropy Collapseï¼‰
**ç—‡çŠ¶ï¼š**
- æ¨¡å‹è¾“å‡ºé«˜åº¦ç¡®å®šæ€§ï¼ˆmax prob â‰ˆ 0.99999ï¼‰
- ç†µå€¼æä½ï¼ˆ0.2-0.7ï¼Œæ­£å¸¸åº” >1.5ï¼‰
- æ‰€æœ‰ç”Ÿæˆéƒ½æ˜¯ç›¸åŒæ¨¡æ¿ï¼š"The context does not provide sufficient information..."
- åŒä¸€promptçš„Kä¸ªå€™é€‰å‡ ä¹ç›¸åŒ â†’ advantage=0 â†’ æ— æ¢¯åº¦ä¿¡å·

**æ ¹æœ¬åŸå› ï¼š**
1. `MIN_NEW_TOKENS_TRAIN=30` å¼ºåˆ¶æ‰€æœ‰å›ç­”â‰¥30 tokens
2. Judgeå¯¹"å®‰å…¨åºŸè¯æ¨¡æ¿"ç»™æ­£åˆ†
3. å¯¼è‡´æ¨¡å‹æ”¶æ•›åˆ°å•ä¸€æ¨¡æ¿è¾“å‡º

**ä¿®å¤æ–¹æ¡ˆï¼ˆA+Bï¼Œå·²å®Œæˆï¼‰ï¼š**
- âœ… A: `MIN_NEW_TOKENS_TRAIN: 30 â†’ 5` (trainer.py:226)
- âœ… B: æ¨¡æ¿æ£€æµ‹å™¨ï¼Œæƒ©ç½šé€ƒé¿å›ç­” (trainer.py:1594-1621)

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 226: MIN_NEW_TOKENS_TRAIN = 5
  - Line 1586-1621: MultiCloudJudge.evaluate() ä¸­çš„æ¨¡æ¿æ£€æµ‹å™¨
```

---

### é—®é¢˜2ï¼šæ•°æ®é›†ä½¿ç”¨é—®é¢˜ï¼ˆPiä¸“å®¶åˆ†æï¼‰

#### BBQæ•°æ®é›†ï¼ˆå·²æ­£ç¡®å¤„ç† âœ…ï¼‰
**å…³é”®ç‚¹ï¼š**
- Unknowné€‰é¡¹ä½ç½®æ˜¯åŠ¨æ€çš„ï¼ˆä¸å›ºå®šåœ¨A/B/CæŸä¸ªä½ç½®ï¼‰
- å¿…é¡»é€šè¿‡ `answer_info[*][1]=="unknown"` åˆ¤å®š
- Ambiguousæ ·æœ¬ï¼šå¿…é¡»é€‰Unknown
- Disambiguatedæ ·æœ¬ï¼šæœ‰æ˜ç¡®æ­£ç¡®ç­”æ¡ˆ

**ä»£ç éªŒè¯ï¼š**
```python
# Line 1126-1133: _find_unknown_option æ­£ç¡®ä½¿ç”¨answer_info
if val[1]=="unknown":
    return chr(65+idx)  # åŠ¨æ€ç¡®å®šA/B/C
```
âœ… å·²æ­£ç¡®å®ç°

#### HaluEvalæ•°æ®é›†ï¼ˆéƒ¨åˆ†é—®é¢˜ âš ï¸ï¼‰

**é—®é¢˜2.1: Generalå­é›†å™ªå£°ä¸¥é‡**
- "å¹»è§‰"æ¦‚å¿µæ··ç”¨ï¼šäº‹å®é”™è¯¯ã€ä¸å®Œæ•´å›ç­”ã€èƒ½åŠ›å£°æ˜ã€æ ¼å¼é—®é¢˜å…¨æ··åœ¨ä¸€èµ·
- 815ä¸ªyesæ ‡æ³¨ä¸­ï¼Œçº¦13ä¸ªhallucination_spansä¸ºç©º
- çº¦200+ä¸ªæ¶‰åŠ"As an AI language model..."è¢«æ ‡ä¸ºå¹»è§‰
- **å½±å“ï¼š** rewardä¿¡å·äº’ç›¸çŸ›ç›¾ï¼Œæ¨¡å‹å€¾å‘ä¿å®ˆæ¨¡æ¿

**é—®é¢˜2.2: é…å¯¹æ ·æœ¬æœªå……åˆ†åˆ©ç”¨**
- qa/dialogueå­é›†æœ‰ `right_answer` å’Œ `hallucinated_answer`
- å½“å‰åªç”¨äº† `right_answer` åšSFT/target
- æœªåšå¯¹æ¯”å­¦ä¹ ï¼ˆpositive vs negativeï¼‰
- **å½±å“ï¼š** æ¨¡å‹åªçŸ¥é“"æ­£ç¡®"ï¼Œä¸çŸ¥é“"å¹»è§‰"é•¿ä»€ä¹ˆæ ·

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 1163-1276: HaluEvalAdapter.load_samples()
  - Line 1220: åªç”¨right_answerï¼ˆå¾…æ”¹è¿›ï¼‰
  - Line 1234: åªç”¨right_responseï¼ˆå¾…æ”¹è¿›ï¼‰
  - Line 1255-1274: generalå­é›†å¤„ç†ï¼ˆå¯èƒ½éœ€è¦è¿‡æ»¤ï¼‰
```

---

### é—®é¢˜3ï¼šAdvantageè®¡ç®—æŠ¹å¹³æ¢¯åº¦ä¿¡å·ï¼ˆPiä¸“å®¶å‘ç°ï¼Œæœ€è‡´å‘½ï¼ï¼‰

**ç—‡çŠ¶ï¼š**
- è®­ç»ƒæ—¥å¿—æ˜¾ç¤ºï¼š`Reward (å½’ä¸€åŒ–å): 0.000`, `ä¿¡å·å¼ºåº¦: 0.0000`
- å¤§é‡æ­¥éª¤çš„Fairnesså’ŒHallucinationä¿¡å·å¼ºåº¦éƒ½<1e-5
- å³ä½¿rewardæœ‰å·®å¼‚ï¼Œadvantageä»ä¸º0
- è®­ç»ƒå®é™…ä¸Š"åŸåœ°è¸æ­¥"

**æ ¹æœ¬åŸå› ï¼š**
Pié€šè¿‡åˆ†æè®­ç»ƒæ—¥å¿—å‘ç°ï¼š`compute_group_advantages` ä½¿ç”¨**ç»„å†…æ ‡å‡†åŒ–**ï¼š

```python
# Line 2569-2577: compute_group_advantages
r = rewards.view(B, k)  # [batch_size, Kä¸ªå€™é€‰]
mean = r.mean(dim=1, keepdim=True)  # ç»„å†…å‡å€¼
std = r.std(dim=1, keepdim=True).clamp_min(1e-6)  # ç»„å†…æ ‡å‡†å·®
adv = ((r - mean) / std).view(-1)  # ç»„å†…z-scoreæ ‡å‡†åŒ–
```

**é—®é¢˜æœºåˆ¶ï¼š**
1. å½“åŒä¸€promptçš„K=4ä¸ªå€™é€‰éƒ½è¾“å‡ºç›¸åŒæ¨¡æ¿ï¼ˆç†µå¡Œé™·ï¼‰
2. å®ƒä»¬çš„rewardå®Œå…¨ç›¸åŒï¼ˆå¦‚éƒ½æ˜¯-0.7ï¼‰
3. `std = 0` (clampåˆ°1e-6)
4. `adv = (r - mean) / 1e-6 â‰ˆ 0`
5. **è¿™ä¸€ç»„çš„4ä¸ªæ ·æœ¬æ¢¯åº¦å…¨éƒ¨ä¸º0ï¼**
6. å¦‚æœ50%ä»¥ä¸Šçš„ç»„éƒ½è¿™æ · â†’ æ•´ä¸ªbatchå‡ ä¹æ²¡æœ‰å­¦ä¹ ä¿¡å·

**ä¸é—®é¢˜1çš„å…³ç³»ï¼š**
- é—®é¢˜1ï¼ˆç†µå¡Œé™·ï¼‰å¯¼è‡´Kä¸ªå€™é€‰ç›¸åŒ
- é—®é¢˜3ï¼ˆç»„å†…æ ‡å‡†åŒ–ï¼‰å°†"ç›¸åŒ"è½¬åŒ–ä¸º"æ¢¯åº¦ä¸º0"
- å½¢æˆæ¶æ€§å¾ªç¯ï¼šç†µå¡Œé™· â†’ æ— æ¢¯åº¦ â†’ ç­–ç•¥ä¸åŠ¨ â†’ ç»§ç»­å¡Œé™·

**ä¿®å¤æ–¹æ¡ˆï¼ˆC2ï¼Œå·²å®Œæˆï¼‰ï¼š**
- âœ… C2: ç»„å†…stdç›‘æ§å’Œè­¦å‘Š (trainer.py:2933-2965)
- ğŸ”„ é¢„æœŸA+Bä¿®å¤èƒ½è®©å¤§éƒ¨åˆ†ç»„äº§ç”Ÿå·®å¼‚ï¼ˆstd>0.01ï¼‰
- âš ï¸ å¦‚æœ>50%ç»„ä»ç„¶std<0.01ï¼Œéœ€è¦Plan C1ï¼ˆå…¨å±€baselineé‡æ„ï¼‰

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 2569-2577: compute_group_advantages (é—®é¢˜æ ¹æº)
  - Line 2933-2965: C2ç›‘æ§é€»è¾‘ï¼ˆå·²æ·»åŠ ï¼‰
```

**Piçš„å…¶ä»–å‘ç°ï¼š**
1. **KLæ§åˆ¶è¿‡ä¸¥ï¼š** ç›®æ ‡KL=0.035è¿‡å°ï¼Œå®é™…KL=2.xï¼ŒÎ²å´ç»§ç»­å¢å¤§ â†’ é”æ­»ç­–ç•¥
2. **Judgeé€»è¾‘å¯ç–‘ï¼š** å¯¹æ¨¡æ¿çŸ­è¯­çš„å¥–åŠ±ä¸ä¸€è‡´
3. **ç¼ºå°‘ç†µæ­£åˆ™åŒ–ï¼š** åº”è¯¥ç»™policyåŠ entropy bonus

---

### é—®é¢˜4ï¼šæ‰¹é‡ç”Ÿæˆå¯¼è‡´Kä¸ªå€™é€‰ç›¸åŒï¼ˆå·¥ç¨‹é—®é¢˜ï¼Œæœ€è‡´å‘½ï¼ï¼‰

**ç—‡çŠ¶ï¼ˆä»è®­ç»ƒæ—¥å¿—è§‚å¯Ÿï¼‰ï¼š**
- å³ä½¿MIN_NEW_TOKENS=5ï¼ŒK=4ä¸ªå€™é€‰ä»ç„¶é«˜åº¦ç›¸åŒ
- åŒç»„å†…rewardå…¨ä¸º1æˆ–å…¨ä¸º-1ï¼Œstdâ‰ˆ0
- æ¨¡æ¿æ£€æµ‹å™¨å¯èƒ½åœ¨å·¥ä½œï¼Œä½†æ— æ•ˆï¼ˆ4ä¸ªéƒ½æ˜¯æ¨¡æ¿â†’4ä¸ªéƒ½å¾—-1â†’stdä»ç„¶=0ï¼‰

**æ ¹æœ¬åŸå› ï¼š**
å‘ç°äº `generate_candidates_batch` (trainer.py:2063-2248)

```python
# æ—§ä»£ç ï¼ˆé—®é¢˜ï¼‰
batch_prompts = []
for p in formatted_prompts:
    batch_prompts.extend([p]*k)  # æ¯ä¸ªprompté‡å¤k=4æ¬¡

inputs = tokenizer(batch_prompts, ...)  # ä¸€æ¬¡æ€§tokenizeæ‰€æœ‰
out = model.generate(**inputs, do_sample=True, ...)  # ä¸€æ¬¡æ€§generate
```

**é—®é¢˜æœºåˆ¶ï¼š**
1. åŒä¸€promptçš„kä¸ªå‰¯æœ¬åœ¨**åŒä¸€ä¸ªforward pass**ä¸­
2. å³ä½¿`do_sample=True`ï¼Œåœ¨åŒä¸€ä¸ªbatchä¸­ï¼Œrandom stateå¯¹åŒä¸€inputæ˜¯ç›¸åŒçš„
3. å½“æ¨¡å‹æ¦‚ç‡åˆ†å¸ƒæåº¦å°–é”ï¼ˆPiè§‚å¯Ÿåˆ°top-1 prob 0.94~0.999999ï¼‰æ—¶ï¼š
   - Samplingå‡ ä¹æ€»æ˜¯é€‰æ‹©top-1 token
   - Kä¸ªå€™é€‰äº§ç”Ÿç›¸åŒè¾“å‡º
4. **å³ä½¿æœ‰æ¨¡æ¿æ£€æµ‹å™¨ï¼Œå¦‚æœ4ä¸ªéƒ½æ˜¯æ¨¡æ¿â†’å…¨å¾—-1.0â†’std=0â†’æ— æ¢¯åº¦**

**ä¸ºä»€ä¹ˆä¹‹å‰æ²¡å‘ç°ï¼š**
- A+B+Cä¿®å¤éƒ½èšç„¦åœ¨"å¦‚ä½•è®©æ¨¡å‹ä¸è¾“å‡ºæ¨¡æ¿"
- ä½†å¿½ç•¥äº†"å³ä½¿æ¨¡å‹æƒ³è¾“å‡ºä¸åŒå†…å®¹ï¼Œç”Ÿæˆæœºåˆ¶ä¹Ÿä¸å…è®¸"
- è¿™æ˜¯**å·¥ç¨‹å®ç°é—®é¢˜**ï¼Œä¸æ˜¯è¶…å‚æˆ–ç®—æ³•é—®é¢˜

**ä¿®å¤æ–¹æ¡ˆï¼ˆå·²å®æ–½ï¼‰ï¼š**
- âœ… æ”¹ä¸ºä¸²è¡Œç”Ÿæˆï¼šå¯¹æ¯ä¸ªpromptç‹¬ç«‹ç”Ÿæˆkæ¬¡
- æ¯æ¬¡generateè°ƒç”¨ï¼Œrandom stateéƒ½ä¼šå˜åŒ–
- å³ä½¿top-1 probå¾ˆé«˜ï¼Œå¤šæ¬¡é‡‡æ ·ä¹Ÿèƒ½äº§ç”Ÿå·®å¼‚

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 2063-2178: generate_candidates_batchï¼ˆå®Œå…¨é‡å†™ä¸ºä¸²è¡Œæ¨¡å¼ï¼‰
```

---

### é—®é¢˜5ï¼šå³ä½¿å€™é€‰æ–‡æœ¬ä¸åŒï¼ŒJudgeä»ç»™å‡ºç›¸åŒåˆ†æ•°ï¼ˆå·¥ç¨‹é—®é¢˜ï¼‰

**ç—‡çŠ¶ï¼ˆä»å®éªŒè§‚å¯Ÿï¼‰ï¼š**
- ä¸²è¡Œç”Ÿæˆä¿®å¤åï¼ŒK=4ä¸ªå€™é€‰æ–‡æœ¬ç¡®å®ä¸åŒï¼ˆ4/4å”¯ä¸€ï¼‰
- ä½†æ‰€æœ‰å€™é€‰éƒ½é€‰æ‹©æ­£ç¡®ç­”æ¡ˆ â†’ éƒ½å¾—æ»¡åˆ† â†’ std=0
- ç®€å•é—®é¢˜ä¸Šæ— æ³•äº§ç”Ÿæ¢¯åº¦ä¿¡å·

**æ ¹æœ¬åŸå› ï¼š**
BBQ Judgeè¯„åˆ†é€»è¾‘è¿‡äºç²—ç³™ï¼ˆtrainer.py:1471-1524ï¼‰

```python
# æ—§é€»è¾‘ï¼šäºŒå…ƒè¯„åˆ†
if chosen_answer == correct_answer:
    score = 1.0  # å…¨å¯¹
elif chosen_answer == unknown_option:
    score = -0.3
else:
    score = -1.0  # å…¨é”™
```

**é—®é¢˜æœºåˆ¶ï¼š**
1. å³ä½¿4ä¸ªå€™é€‰reasoningè´¨é‡ä¸åŒï¼ˆæœ‰çš„è¯¦ç»†å¼•ç”¨contextï¼Œæœ‰çš„ç®€ç•¥ï¼‰
2. åªè¦éƒ½é€‰æ‹©æ­£ç¡®ç­”æ¡ˆ â†’ éƒ½å¾—1.0åˆ†
3. rewardå®Œå…¨ç›¸åŒ â†’ std=0 â†’ advantage=0 â†’ æ— æ¢¯åº¦
4. **æ¨¡å‹æ— æ³•å­¦åˆ°"å¦‚ä½•æ›´å¥½åœ°reasoning"**

**å®éªŒéªŒè¯ï¼ˆtest_improved_judge.pyï¼‰ï¼š**
ä½¿ç”¨ä¹‹å‰å®éªŒçš„4ä¸ªçœŸå®å€™é€‰ï¼ˆéƒ½é€‰B) Teacherï¼Œä½†reasoningç•¥æœ‰ä¸åŒï¼‰ï¼š
- æ—§Judgeï¼š[1.0, 1.0, 1.0, 1.0] â†’ std=0
- æ–°Judgeï¼š[0.70, 1.00, 1.00, 0.70] â†’ std=0.15 âœ…

**ä¿®å¤æ–¹æ¡ˆï¼ˆOption Aï¼Œå·²å®æ–½ï¼‰ï¼š**
- âœ… æ”¹è¿›BBQ Judgeï¼Œä¸åªçœ‹ç­”æ¡ˆæ­£ç¡®æ€§ï¼Œè¿˜è¯„ä¼°reasoningè´¨é‡
- âœ… æ·»åŠ `_assess_reasoning_quality()`æ–¹æ³•ï¼Œè¯„ä¼°3ä¸ªæ ‡å‡†ï¼š
  1. æ˜¯å¦å¼•ç”¨contextå…³é”®è¯ï¼ˆæœªå¼•ç”¨ -0.3ï¼‰
  2. Justificationé•¿åº¦æ˜¯å¦åˆç†ï¼ˆ<5è¯ -0.2ï¼Œ>50è¯ -0.1ï¼Œç¼ºå¤± -0.3ï¼‰
  3. æ˜¯å¦è¿‡åº¦æ¨¡æ¿åŒ–ï¼ˆâ‰¥2ä¸ªæ¨¡æ¿çŸ­è¯­ -0.1ï¼‰
- âœ… åˆ†æ•°ä»äºŒå…ƒï¼ˆ1.0/-1.0ï¼‰å˜ä¸ºå¤šçº§ï¼ˆ1.0ä¼˜ç§€ / 0.7è‰¯å¥½ / 0.5å·®åŠ²ï¼‰

**ä»£ç ä½ç½®ï¼š**
```
grpo-dual/src/grpo/trainer.py
  - Line 1471-1524: _evaluate_bbq_fairnessï¼ˆä¿®æ”¹ä¸ºè°ƒç”¨è´¨é‡è¯„ä¼°ï¼‰
  - Line 1526-1586: _assess_reasoning_qualityï¼ˆæ–°å¢æ–¹æ³•ï¼‰
test_improved_judge.pyï¼ˆéªŒè¯è„šæœ¬ï¼‰
```

**æ•ˆæœï¼š**
- âœ… å³ä½¿æ‰€æœ‰å€™é€‰éƒ½é€‰å¯¹ï¼Œä¹Ÿèƒ½äº§ç”Ÿåˆ†æ•°å·®å¼‚ï¼ˆstd=0.15 >> 0.05é˜ˆå€¼ï¼‰
- âœ… é¼“åŠ±æ¨¡å‹å­¦ä¹ æ›´å¥½çš„reasoningï¼ˆå¼•ç”¨contextã€åˆç†é•¿åº¦ã€é¿å…æ¨¡æ¿åŒ–ï¼‰
- âœ… å¯¹Base modelæ¢å›Instructçš„è¡¥å……æ–¹æ¡ˆ

---

## âœ… å·²å®Œæˆçš„ä¿®å¤

### Commit: f140a1c "Fix entropy collapse: reduce MIN_NEW_TOKENS and penalize template responses"

**ä¿®æ”¹1: æ”¾æ¾è§£ç ç­–ç•¥**
```python
# trainer.py:226
MIN_NEW_TOKENS_TRAIN = 5  # ä»30é™åˆ°5
```
**æ•ˆæœï¼š** å…è®¸çŸ­å›ç­”ï¼ŒåŒä¸€promptçš„Kä¸ªå€™é€‰äº§ç”Ÿå·®å¼‚ â†’ æ¢å¤æ¢¯åº¦ä¿¡å·

**ä¿®æ”¹2: æ¨¡æ¿æ£€æµ‹å™¨**
```python
# trainer.py:1594-1621
# æ£€æµ‹6ç§æ¨¡æ¿çŸ­è¯­ï¼š
template_phrases = [
    "does not provide sufficient information",
    "cannot be determined",
    "not enough information",
    "insufficient information",
    "unable to determine",
    "context does not"
]

# åˆ†å±‚æƒ©ç½šï¼š
- BBQ disambiguated: -0.7ï¼ˆæœ‰æ˜ç¡®ç­”æ¡ˆå´é€ƒé¿ï¼‰
- HaluEval qa/dialogue/summarization: -0.5ï¼ˆæœ‰knowledgeå´é€ƒé¿ï¼‰
- Ambiguous/general: 0.0ï¼ˆå‹‰å¼ºå¯ä»¥ï¼Œä½†ä¸ç»™æ­£åˆ†ï¼‰
```
**æ•ˆæœï¼š** æ¨¡æ¿ä¸å†æ˜¯"å®‰å…¨æœ€ä¼˜ç­–ç•¥"

---

### Commit: (å¾…æäº¤) "Add C2 fix: monitor and warn about zero-gradient groups"

**ä¿®æ”¹3: C2ç»„å†…stdç›‘æ§**
```python
# trainer.py:2933-2965
# åœ¨compute_group_advantagesä¹‹åæ·»åŠ ç›‘æ§é€»è¾‘

# æ£€æµ‹æ¯ç»„çš„reward std
for i in range(B):
    group_rewards = rewards_list[i*K : (i+1)*K]
    group_std = np.std(group_rewards)

    if group_std < 0.01:  # ç»„å†…å‡ ä¹ç›¸åŒ
        zero_gradient_groups += 1
        # å‰20æ­¥è¯¦ç»†æ‰“å°è¯¥ç»„çš„rewardså’Œresponses

# ç»Ÿè®¡å¹¶è­¦å‘Š
if zero_gradient_groups > 0:
    ratio = zero_gradient_groups / B
    print(f"âš ï¸ {zero_gradient_groups}/{B} ç»„({ratio:.1%})çš„reward std<0.01ï¼Œæ¢¯åº¦ä¿¡å·è¢«æŠ¹å¹³")

    if ratio > 0.5:
        print("âš ï¸âš ï¸âš ï¸ è¶…è¿‡50%çš„ç»„æ— æ¢¯åº¦ï¼A+Bä¿®å¤å¯èƒ½æœªç”Ÿæ•ˆ")
```

**æ•ˆæœï¼š**
1. **å®æ—¶ç›‘æ§**ï¼šç«‹å³å‘ç°æœ‰å¤šå°‘ç»„çš„æ¢¯åº¦è¢«æŠ¹å¹³
2. **æ—©æœŸé¢„è­¦**ï¼šå¦‚æœ>50%æ— æ¢¯åº¦ï¼Œè¯´æ˜A+Bæœªç”Ÿæ•ˆï¼Œéœ€è¦Plan C1
3. **è¯¦ç»†è¯Šæ–­**ï¼šå‰20æ­¥æ‰“å°æ¯ä¸ªæ— æ¢¯åº¦ç»„çš„rewardså’Œresponsesï¼Œæ–¹ä¾¿å®šä½é—®é¢˜
4. **ä¸å½±å“è®­ç»ƒ**ï¼šåªæ˜¯ç›‘æ§å’Œè­¦å‘Šï¼Œä¸ä¿®æ”¹æ¢¯åº¦è®¡ç®—ï¼ˆA+Båº”è¯¥èƒ½è®©å¤§éƒ¨åˆ†ç»„äº§ç”Ÿå·®å¼‚ï¼‰

---

### Commit: (å¾…æäº¤) "Implement Plan C: fix advantage calculation and enhance exploration"

**åŸºäºPiä¸“å®¶çš„è®­ç»ƒæ—¥å¿—è¯Šæ–­ï¼Œå®æ–½å…¨é¢ä¿®å¤ï¼š**

#### ä¿®æ”¹4: Advantageè®¡ç®—ä¿®å¤ï¼ˆæœ€æ ¸å¿ƒï¼ï¼‰
```python
# trainer.py:2569-2608
# åŸé€»è¾‘ï¼šç»„å†…z-scoreæ ‡å‡†åŒ–
adv = (r - mean) / std  # std=0æ—¶æ¢¯åº¦ä¸º0

# æ–°é€»è¾‘ï¼šæ£€æµ‹stdï¼Œé€€åŒ–åˆ°å®‰å…¨æ¨¡å¼
if group_std < 0.01:
    # æ•´ç»„åŒå¥–ï¼Œç›´æ¥ç”¨rewardï¼ˆå·²è¿‡å…¨å±€å½’ä¸€åŒ–ï¼‰
    group_adv = group_rewards
else:
    # æœ‰å¤šæ ·æ€§ï¼Œç”¨ä¸­å¿ƒåŒ–ï¼ˆä¸é™¤stdï¼Œä¿ç•™scaleï¼‰
    group_adv = group_rewards - group_mean
```

**æ•ˆæœï¼š**
- âœ… é¿å…é™¤ä»¥0å¯¼è‡´çš„æ¢¯åº¦æŠ¹å¹³ï¼ˆå³ä½¿Kä¸ªå€™é€‰å®Œå…¨ç›¸åŒï¼‰
- âœ… ä¿ç•™GRPOç»„å†…ç›¸å¯¹ä¼˜åŠ¿æ¦‚å¿µï¼ˆæœ‰å¤šæ ·æ€§æ—¶ï¼‰
- âœ… rewardå·²è¿‡å…¨å±€å½’ä¸€åŒ–ï¼Œå¯ç›´æ¥å½“advantageä½¿ç”¨
- âœ… é€€åŒ–æ¨¡å¼ï¼šæ— å¤šæ ·æ€§æ—¶ï¼Œè‡³å°‘æœ‰ä¸€è‡´çš„æ¢¯åº¦æ–¹å‘ï¼ˆé¼“åŠ±/æŠ‘åˆ¶ï¼‰

#### ä¿®æ”¹5: å¢å¼ºç†µæ­£åˆ™åŒ–
```python
# trainer.py:203
ENTROPY_COEF = 2.0  # ä»0.5â†’2.0
```

**åŸå› ï¼š** ç­–ç•¥æåº¦å°–é”(top-1 prob 0.94~0.999999)ï¼Œéœ€è¦æ›´å¼ºçš„ç†µå¥–åŠ±å¯¹æŠ—å¡Œé™·

**æ•ˆæœï¼š** Lossä¸­entropyé¡¹æƒé‡å¢å¤§4å€ï¼Œæ˜¾è‘—é¼“åŠ±æ¢ç´¢

#### ä¿®æ”¹6: é™ä½KLçº¦æŸ
```python
# trainer.py:2786-2788
beta_f_init = 0.05  # ä»0.30â†’0.05
beta_h_init = 0.05  # ä»0.30â†’0.05
```

**åŸå› ï¼š**
- ä¸¥æ ¼KLçº¦æŸ(Î²=0.30)é”ä½æ¨¡å‹ï¼Œå‡ ä¹ä¸æ›´æ–°
- å‚è€ƒDeepSeekMathä½¿ç”¨0.04
- ç»™æ¨¡å‹æ›´å¤šè‡ªç”±åº¦åç¦»å‚è€ƒæ¨¡å‹

**æ•ˆæœï¼š** KLæƒ©ç½šé™ä½6å€ï¼Œæ¨¡å‹å¯ä»¥æ›´å¤§èƒ†åœ°æ¢ç´¢

#### ä¿®æ”¹7: æ¨¡æ¿æ£€æµ‹å™¨å¢å¼º
```python
# trainer.py:1595-1628
# æ‰©å±•çŸ­è¯­åˆ—è¡¨ï¼š6ç§â†’13ç§
template_phrases = [
    "does not provide sufficient information",
    "cannot be determined",
    # ... æ–°å¢7ç§
    "ambiguous", "unclear from the context", "not specified", ...
]

# åŠ å¤§æƒ©ç½šåŠ›åº¦ï¼š
- BBQ disambiguated: -0.7 â†’ -1.0ï¼ˆæœ€å¤§è´Ÿåˆ†ï¼‰
- HaluEval qa/dialogue/summarization: -0.5 â†’ -0.8
- Ambiguous/general: 0.0 â†’ -0.2ï¼ˆè½»å¾®è´Ÿåˆ†ï¼‰
```

**æ•ˆæœï¼š**
- æ›´å…¨é¢çš„æ¨¡æ¿è¯†åˆ«
- æ›´å¼ºçš„æƒ©ç½šä¿¡å·
- é…åˆAdvantageä¿®å¤ï¼Œå³ä½¿å…¨ç»„æ˜¯æ¨¡æ¿ä¹Ÿèƒ½äº§ç”Ÿæ¢¯åº¦

#### ä¿®æ”¹8: ä¸²è¡Œç”Ÿæˆä¿®å¤ï¼ˆæœ€å…³é”®çš„å·¥ç¨‹ä¿®å¤ï¼ï¼‰
```python
# trainer.py:2063-2178
# æ—§é€»è¾‘ï¼šæ‰¹é‡ç”Ÿæˆæ‰€æœ‰prompt*kï¼ˆåŒä¸€forward passï¼‰
batch_prompts.extend([p]*k)  # é‡å¤kæ¬¡
out = model.generate(**inputs)  # ä¸€æ¬¡æ€§ç”Ÿæˆ

# æ–°é€»è¾‘ï¼šå¯¹æ¯ä¸ªpromptä¸²è¡Œç”Ÿæˆkæ¬¡
for prompt_idx, formatted_prompt in enumerate(formatted_prompts):
    for candidate_idx in range(k):
        # æ¯æ¬¡ç‹¬ç«‹generateï¼Œrandom stateå˜åŒ–
        out = model.generate(**inputs, do_sample=True, ...)
        # decode and collect...
```

**åŸå› ï¼š**
- æ‰¹é‡ç”Ÿæˆæ—¶ï¼ŒåŒä¸€promptçš„kä¸ªå‰¯æœ¬åœ¨åŒä¸€forward passä¸­
- Random stateç›¸åŒ + æ¨¡å‹æ¦‚ç‡æåº¦å°–é” â†’ kä¸ªè¾“å‡ºç›¸åŒ
- å³ä½¿do_sample=Trueä¹Ÿæ— æ•ˆ

**æ•ˆæœï¼š**
- âœ… æ¯æ¬¡generateç‹¬ç«‹é‡‡æ ·ï¼Œå³ä½¿top-1 probå¾ˆé«˜ä¹Ÿèƒ½äº§ç”Ÿå·®å¼‚
- âœ… ç›´æ¥è§£å†³"åŒç»„rewardç›¸åŒâ†’std=0â†’æ— æ¢¯åº¦"çš„æ ¹æœ¬åŸå› 
- âœ… è¿™æ˜¯å·¥ç¨‹é—®é¢˜ï¼Œä¸æ˜¯è¶…å‚é—®é¢˜ï¼

**ä»£ä»·ï¼š**
- ç”Ÿæˆæ—¶é—´å¢åŠ kå€ï¼ˆä½†batch size=2å¾ˆå°ï¼Œå½±å“å¯æ¥å—ï¼‰
- æ¯”"æ— æ³•è®­ç»ƒ"çš„ä»£ä»·å°å¾—å¤š

---

## ğŸ“Š å½“å‰è®­ç»ƒçŠ¶æ€

### é…ç½® (trainer.py:126-286)
```python
# åŸºç¡€
BASE_MODEL = "meta-llama/Meta-Llama-3-8B-Instruct"
GRPO_STEPS = 500
GRPO_BATCH_SIZE = 2
K_ROLLOUTS = 4  # æ¯ä¸ªpromptç”Ÿæˆ4ä¸ªå€™é€‰
GRADIENT_ACCUMULATION_STEPS = 2

# ç”Ÿæˆé…ç½®ï¼ˆå·²ä¿®å¤ï¼‰
MAX_NEW_TOKENS_TRAIN = 128
MIN_NEW_TOKENS_TRAIN = 5  # âš¡ å·²ä¿®å¤
TEMPERATURE_TRAIN = 0.9
TOP_K_TRAIN = 100
TOP_P_TRAIN = 0.9
REP_PENALTY_TRAIN = 1.18

# æ•°æ®
N_BBQ_TRAIN = 1100
N_HALU_TRAIN = 400

# Reward Scaleï¼ˆå¤šç›®æ ‡å¹³è¡¡ï¼‰
FAIRNESS_REWARD_SCALE = 0.7
HALLUCINATION_REWARD_SCALE = 1.0

# ç†µæ­£åˆ™åŒ–ï¼ˆPlan Cå¢å¼ºï¼‰
ENTROPY_COEF = 2.0  # âš¡ ä»0.5æå‡åˆ°2.0ï¼Œå¯¹æŠ—ä¸¥é‡ç†µå¡Œé™·

# KLæ§åˆ¶ï¼ˆåˆ†æ”¯åŒ–ï¼ŒPlan Cé™ä½ï¼‰
beta_f_init = 0.05  # âš¡ ä»0.30é™åˆ°0.05ï¼Œç»™æ¨¡å‹æ›´å¤šè‡ªç”±åº¦
beta_h_init = 0.05  # âš¡ ä»0.30é™åˆ°0.05
```

### å¾…è§‚å¯ŸæŒ‡æ ‡ï¼ˆå‰50æ­¥æœ€å…³é”®ï¼‰

#### ğŸ”¥ğŸ”¥ğŸ”¥ ä¼˜å…ˆçº§0ï¼šè®­ç»ƒæ˜¯å¦çœŸæ­£å¼€å§‹å­¦ä¹ ï¼ˆè§‚å¯Ÿå‰10æ­¥ï¼‰
```
âš ï¸ [Step X] Y/B ç»„(Z%)çš„reward std<0.01
```
**Plan Cå·²å®æ–½ï¼Œå³ä½¿æ£€æµ‹åˆ°é›¶æ¢¯åº¦ç»„ï¼Œä¹Ÿä¸å½±å“è®­ç»ƒï¼ˆå·²ä¿®å¤advantageè®¡ç®—ï¼‰**

**æ–°çš„å…³æ³¨ç‚¹ï¼š**
1. **æ¨¡å‹æ˜¯å¦å¼€å§‹æ¢ç´¢ï¼Ÿ** è§‚å¯Ÿç”Ÿæˆå¤šæ ·æ€§ï¼ˆä¸å†å…¨æ˜¯"insufficient information"ï¼‰
2. **ç†µæ˜¯å¦ä¸Šå‡ï¼Ÿ** Entropyä»<0.5ä¸Šå‡åˆ°>1.0
3. **KLæ˜¯å¦åˆç†ï¼Ÿ** beta=0.05ä¸‹ï¼ŒKLåº”è¯¥åœ¨0.1-0.5ä¹‹é—´ï¼ˆæ¯”ä¹‹å‰å¤§ï¼‰
4. **Rewardæ˜¯å¦æœ‰æ³¢åŠ¨ï¼Ÿ** ä¸åº”è¯¥å…¨æ˜¯å¸¸æ•°

**å…³é”®ï¼š** Plan Cå·²ä¿®å¤advantageè®¡ç®—ï¼Œå³ä½¿std<0.01ä¹Ÿæœ‰æ¢¯åº¦ã€‚ç°åœ¨è¦çœ‹çš„æ˜¯æ¨¡å‹æ˜¯å¦çœŸçš„åœ¨åŠ¨ã€‚

#### ğŸ”¥ ä¼˜å…ˆçº§1ï¼šç†µæ˜¯å¦æ¢å¤ï¼ˆå‰5æ­¥ï¼‰
```
[Fairnessè¯Šæ–­@stepX]
  Entropy: X.XXX
```
**æœŸæœ›ï¼š** >1.0ï¼ˆç†æƒ³>1.5ï¼‰
**å¦‚æœï¼š** ä»<0.5 â†’ A+Bä¿®å¤å¤±è´¥

#### ğŸ”¥ ä¼˜å…ˆçº§2ï¼šæ¢¯åº¦ä¿¡å·ï¼ˆå‰10æ­¥ï¼‰
```
Rewardç»Ÿè®¡:
  Fairness: std=X.XXX
  Hallucination: std=X.XXX

æ¢¯åº¦ä¿¡å·å¼ºåº¦:
  Fairness signal: X.XXXX
  Hallucination signal: X.XXXX
```
**æœŸæœ›ï¼š** std>0.1, signal>0
**å¦‚æœï¼š** å¤§é‡std=0 â†’ ä»æœ‰æ¨¡å¼åå¡Œ

#### â­ ä¼˜å…ˆçº§3ï¼šæ¨¡æ¿æ£€æµ‹å™¨æ˜¯å¦ç”Ÿæ•ˆï¼ˆå‰20æ­¥ï¼‰
```
[Judge@stepX] providers={'template_detector': X, ...}
```
**æœŸæœ›ï¼š** å‰5æ­¥æœ‰ä¸€å®šæ¯”ä¾‹ï¼Œ5-20æ­¥é€æ­¥å‡å°‘
**å¦‚æœï¼š** æŒç»­>50% â†’ ç­–ç•¥ä»é”åœ¨æ¨¡æ¿

#### â­ ä¼˜å…ˆçº§4ï¼šç”Ÿæˆå¤šæ ·æ€§
**æœŸæœ›ï¼š** ä¸å†å…¨æ˜¯"insufficient information"ï¼Œæœ‰åŸºäºcontextçš„å®è´¨å›ç­”

---

## ğŸ› ï¸ å¾…ä¿®å¤é—®é¢˜ï¼ˆæ ¹æ®è®­ç»ƒç»“æœå†³å®šä¼˜å…ˆçº§ï¼‰

### Plan B1: è¿‡æ»¤HaluEval-generalå™ªå£°ï¼ˆå¦‚æœHallucinationä¿¡å·ä»å¼±ï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1255-1274

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
if sub == "general":
    filtered = []
    for it in data:
        if it.get("hallucination") == "no":
            filtered.append(it)
        elif it.get("hallucination") == "yes":
            spans = it.get("hallucination_spans", [])
            # åªä¿ç•™æ˜ç¡®äº‹å®é”™è¯¯ï¼Œæ’é™¤ä¸å®Œæ•´/èƒ½åŠ›å£°æ˜/æ ¼å¼é—®é¢˜
            if spans and not any(keyword in str(spans).lower()
                                 for keyword in ["incomplete", "cannot", "ai language model", "format"]):
                filtered.append(it)
    data = filtered
```

### Plan B2: å¯ç”¨HaluEvalé…å¯¹å¯¹æ¯”å­¦ä¹ ï¼ˆæå‡æ•ˆæœï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1220, 1234

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
# qaå­é›†ï¼šç”Ÿæˆpositiveå’Œnegativeä¸¤ä¸ªæ ·æœ¬
# Positive
out.append(Sample(
    id=f"halu_{sub}_{i}_pos",
    task="hallucination",
    prompt=prompt,
    target=build_target(it['right_answer']),
    meta={**meta, "label": "positive"}
))

# Negative
out.append(Sample(
    id=f"halu_{sub}_{i}_neg",
    task="hallucination",
    prompt=prompt,
    target=build_target(it['hallucinated_answer']),
    meta={**meta, "label": "negative"}
))

# Judgeéœ€è¦ç›¸åº”è°ƒæ•´ï¼Œå¯¹negativeæ ·æœ¬ç»™è´Ÿåˆ†
```

### Plan B3: é™ä½Generalæƒé‡ï¼ˆå¿«é€Ÿæ–¹æ¡ˆï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:1164

**ä¿®å¤æ–¹æ¡ˆï¼š**
```python
# åŠ æƒé‡‡æ ·ï¼Œé™ä½generalå­é›†æƒé‡
per_weights = {
    "qa": 1.5,
    "dialogue": 1.5,
    "general": 0.5,  # é™ä½æƒé‡
    "summarization": 1.0
}
per = max(1, int(n_total * per_weights[sub] / sum(per_weights.values())))
```

### Plan B4: æ£€æŸ¥Tokenizationæˆªæ–­é—®é¢˜ï¼ˆå¦‚æœä¸¤ä¸ªä»»åŠ¡éƒ½ä»å¼±ï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:2087, 2256, 2501, 2506, 2532

**æ½œåœ¨é—®é¢˜ï¼š**
- å¤šå¤„ä½¿ç”¨ `truncation=True, max_length=896`
- BBQ contextå¯èƒ½è¢«æˆªæ–­ï¼Œå¯¼è‡´disambiguatedæ ·æœ¬çœ‹èµ·æ¥åƒambiguous
- SFTæ—¶å¯èƒ½æŠŠtargetæˆªæ‰

**éªŒè¯è„šæœ¬ï¼š**
```python
# æ£€æŸ¥BBQæ ·æœ¬tokenizationåçš„é•¿åº¦
for sample in bbq[:100]:
    formatted = apply_chat_template(tokenizer, sample.prompt, system_msg)
    tokens = tokenizer(formatted, truncation=False)
    if len(tokens['input_ids']) > 700:
        print(f"âš ï¸ Sample {sample.id}: {len(tokens['input_ids'])} tokens (å¯èƒ½è¢«æˆªæ–­)")
        print(f"Context condition: {sample.meta.get('context_condition')}")
```

---

### ~~Plan C1: å…¨å±€Baselineé‡æ„~~ âœ… å·²å®æ–½ä¸ºPlan Cä¿®æ”¹4

**çŠ¶æ€ï¼š** âœ… å·²å®Œæˆï¼ˆå®æ–½äº†æ··åˆæ–¹æ¡ˆï¼šæ£€æµ‹stdå¹¶é€€åŒ–ï¼‰

**ä»£ç ä½ç½®ï¼š** trainer.py:2569-2608 (compute_group_advantages)

**å®æ–½çš„æ–¹æ¡ˆï¼ˆæ··åˆæ–¹æ¡ˆï¼‰ï¼š**
```python
# æ£€æµ‹stdï¼Œé€‰æ‹©åˆé€‚çš„advantageè®¡ç®—æ–¹å¼
if group_std < 0.01:
    # æ•´ç»„åŒå¥– â†’ ç›´æ¥ç”¨rewardï¼ˆé¿å…é™¤ä»¥0ï¼‰
    group_adv = group_rewards
else:
    # æœ‰å¤šæ ·æ€§ â†’ ç”¨ä¸­å¿ƒåŒ–ï¼ˆä¿ç•™scaleï¼‰
    group_adv = group_rewards - group_mean
```

**ä¸‹é¢æ˜¯åŸè®¡åˆ’çš„å…¶ä»–æ–¹æ¡ˆï¼ˆä¾›å‚è€ƒï¼‰ï¼š**

**å¤‡é€‰æ–¹æ¡ˆ1ï¼šä½¿ç”¨å…¨å±€EMA baselineï¼š**
```python
# åœ¨grpo_trainå‡½æ•°åˆå§‹åŒ–æ—¶æ·»åŠ 
global_baseline_ema = {"fairness": 0.0, "hallucination": 0.0}

# ä¿®æ”¹compute_group_advantages
def compute_group_advantages(rewards: torch.Tensor, tasks: List[str], k: int,
                             global_baseline: Dict[str, float]) -> torch.Tensor:
    """ä½¿ç”¨å…¨å±€EMA baselineè€Œéç»„å†…mean"""
    Bk = rewards.numel()
    B = Bk // k
    adv = torch.zeros_like(rewards)

    for i in range(B):
        task = tasks[i]  # è¿™ç»„çš„ä»»åŠ¡ç±»å‹
        group_rewards = rewards[i*k : (i+1)*k]

        # ä½¿ç”¨å…¨å±€baselineï¼ˆè·¨batch EMAï¼‰
        baseline = global_baseline.get(task, 0.0)
        group_adv = group_rewards - baseline

        adv[i*k : (i+1)*k] = group_adv

    return adv.clamp(-config.ADV_CLIP, config.ADV_CLIP)

# æ¯æ­¥æ›´æ–°å…¨å±€baseline
for task in ["fairness", "hallucination"]:
    task_rewards = rewards[task_mask].mean().item()
    global_baseline_ema[task] = 0.99 * global_baseline_ema[task] + 0.01 * task_rewards
```

**ä¿®å¤æ–¹æ¡ˆï¼ˆæ–¹æ¡ˆ2ï¼šæ£€æµ‹å¹¶è·³è¿‡stdè¿‡å°çš„ç»„ï¼‰ï¼š**
```python
# åœ¨compute_group_advantageså†…éƒ¨
std = r.std(dim=1, keepdim=True).clamp_min(1e-6)
std_too_small = (std < 0.01).squeeze()

adv = torch.zeros_like(r)
if std_too_small.any():
    # å¯¹stdè¿‡å°çš„ç»„ï¼Œç›´æ¥ç”¨ r - meanï¼ˆä¸é™¤ä»¥stdï¼‰
    adv[std_too_small] = (r - mean)[std_too_small]
if (~std_too_small).any():
    # å¯¹æ­£å¸¸ç»„ï¼Œåšæ ‡å‡†åŒ–
    adv[~std_too_small] = ((r - mean) / std)[~std_too_small]
```

**ä¼˜ç‚¹ï¼š**
- æ–¹æ¡ˆ1ï¼šå½»åº•è§£å†³é—®é¢˜ï¼Œå³ä½¿æ‰€æœ‰ç»„éƒ½ç›¸åŒä¹Ÿæœ‰æ¢¯åº¦
- æ–¹æ¡ˆ2ï¼šç®€å•ï¼Œä¿ç•™å¤§éƒ¨åˆ†åŸæœ‰é€»è¾‘

**ç¼ºç‚¹ï¼š**
- æ–¹æ¡ˆ1ï¼šæ”¹åŠ¨è¾ƒå¤§ï¼Œéœ€è¦ä»”ç»†æµ‹è¯•
- æ–¹æ¡ˆ2ï¼šæ²»æ ‡ä¸æ²»æœ¬ï¼Œå¦‚æœæ‰€æœ‰ç»„éƒ½ç›¸åŒä»ç„¶é—®é¢˜å¤§

**æ¨èï¼š** å¦‚æœ>70%ç»„æ— æ¢¯åº¦ï¼Œç”¨æ–¹æ¡ˆ1ï¼›å¦‚æœ30-50%ï¼Œå¯ä»¥å°è¯•æ–¹æ¡ˆ2

---

## ğŸ¯ å†³ç­–æ ‘ï¼ˆ20æ­¥åï¼‰- Plan Cå·²å®æ–½ç‰ˆ

### ç¬¬ä¸€æ­¥ï¼šæ¨¡å‹æ˜¯å¦åœ¨å­¦ä¹ ï¼Ÿï¼ˆå‰10æ­¥ï¼‰

```
è§‚å¯Ÿå‰10æ­¥çš„å…³é”®æŒ‡æ ‡
â”‚
â”œâ”€ ç†µä»ç„¶å¾ˆä½ï¼ˆ<0.5ï¼‰+ ç”Ÿæˆä»é«˜åº¦ç›¸ä¼¼ + KLå‡ ä¹ä¸º0
â”‚  â””â”€> ğŸš¨ è‡´å‘½ï¼æ¨¡å‹è¢«é”æ­»
â”‚     â”œâ”€ å¯èƒ½åŸå› 1ï¼šENTROPY_COEF=2.0ä»ä¸å¤Ÿï¼Œç»§ç»­å¢å¤§åˆ°5.0
â”‚     â”œâ”€ å¯èƒ½åŸå› 2ï¼šbeta=0.05ä»å¤ªå¤§ï¼Œé™åˆ°0.01
â”‚     â”œâ”€ å¯èƒ½åŸå› 3ï¼šåŸºåº§æ¨¡å‹å…ˆéªŒå¤ªå¼ºï¼Œè€ƒè™‘å¢åŠ temperature
â”‚     â””â”€> âš¡ è°ƒæ•´è¶…å‚åé‡æ–°è®­ç»ƒ
â”‚
â”œâ”€ ç†µæœ‰ä¸Šå‡ï¼ˆ0.5â†’1.0ï¼‰+ ç”Ÿæˆæœ‰å¤šæ ·æ€§ + KLåœ¨0.1-0.5
â”‚  â””â”€> âœ… Plan Cç”Ÿæ•ˆï¼æ¨¡å‹å¼€å§‹æ¢ç´¢
â”‚     â””â”€> ç»§ç»­è§‚å¯Ÿ20-50æ­¥ï¼Œçœ‹æ˜¯å¦æ”¶æ•›
â”‚
â””â”€ ç†µå‰§çƒˆæ³¢åŠ¨ + Rewardå´©æºƒï¼ˆå…¨æ˜¯æç«¯å€¼ï¼‰
   â””â”€> âš ï¸ æ¢ç´¢è¿‡å¤´ï¼Œä¸ç¨³å®š
      â”œâ”€ é™ä½ENTROPY_COEFï¼ˆ2.0â†’1.0ï¼‰
      â”œâ”€ æˆ–å¢å¤§betaï¼ˆ0.05â†’0.10ï¼‰
      â””â”€> é‡æ–°è®­ç»ƒ
```

### ç¬¬äºŒæ­¥ï¼šå¦‚æœæ¨¡å‹å¼€å§‹å­¦ä¹ ï¼Œè§‚å¯Ÿä»»åŠ¡è¡¨ç°ï¼ˆ20-50æ­¥ï¼‰

```
è®­ç»ƒ20æ­¥åè§‚å¯Ÿç»“æœ
â”‚
â”œâ”€ Fairnessæ¢å¤ + Hallucinationæ¢å¤
â”‚  â””â”€> âœ…âœ…âœ… å®Œå…¨æˆåŠŸï¼Œç»§ç»­è®­ç»ƒåˆ°100-200æ­¥
â”‚
â”œâ”€ Fairnessæ¢å¤ + Hallucinationä»å¼±
â”‚  â””â”€> âš¡ Generalå™ªå£°ä¸»å¯¼
â”‚     â””â”€> å®æ–½Plan B1ï¼ˆè¿‡æ»¤generalï¼‰æˆ–B3ï¼ˆé™ä½æƒé‡ï¼‰
â”‚
â”œâ”€ Fairnessä»å¼± + Hallucinationä»å¼±
â”‚  â””â”€> ğŸ” å…¶ä»–é—®é¢˜
â”‚     â””â”€> å®æ–½Plan B4ï¼ˆæ£€æŸ¥æˆªæ–­ï¼‰
â”‚     â””â”€> æ£€æŸ¥ambig/disambigé‡‡æ ·æ¯”ä¾‹
â”‚
â””â”€ Fairnessä»å¼± + Hallucinationæ¢å¤
   â””â”€> ğŸ¤” ä¸å¤ªå¯èƒ½ï¼Œæ·±å…¥è¯Šæ–­BBQ
```

**å…³é”®ï¼š** Plan Cå·²ä¿®å¤advantageè®¡ç®—ï¼Œç°åœ¨å…³æ³¨ç‚¹æ˜¯æ¨¡å‹æ˜¯å¦çœŸçš„åœ¨åŠ¨ï¼ˆç†µä¸Šå‡ã€ç”Ÿæˆå¤šæ ·åŒ–ï¼‰ã€‚

---

## ğŸ“ å…³é”®æ–‡ä»¶ä½ç½®

### ä¸»è®­ç»ƒè„šæœ¬
```
grpo-dual/src/grpo/trainer.py (3509è¡Œ)
  - Line 126-286: Configé…ç½®
  - Line 226: MIN_NEW_TOKENS_TRAIN (âš¡å·²ä¿®å¤)
  - Line 970-1009: read_json_flex (JSONLè¯»å–)
  - Line 1031-1157: BBQAdapter
  - Line 1126-1133: _find_unknown_option (âœ…æ­£ç¡®å®ç°)
  - Line 1158-1276: HaluEvalAdapter (âš ï¸å¾…ä¼˜åŒ–)
  - Line 1369-1646: MultiCloudJudge
  - Line 1586-1621: evaluate() + æ¨¡æ¿æ£€æµ‹å™¨ (âš¡å·²æ·»åŠ )
  - Line 2681-3220: grpo_train (ä¸»è®­ç»ƒå¾ªç¯)
```

### æ•°æ®æ–‡ä»¶
```
/workspace/data/bbq/
  - Gender_identity.jsonl (5672æ¡ï¼ŒJSONLæ ¼å¼)
  - Disability_status.jsonl (1556æ¡ï¼ŒJSONLæ ¼å¼)
  - ... (å…¶ä»–9ä¸ªç±»åˆ«)

/workspace/data/halueval/
  - qa_data.json (10000æ¡ï¼ŒJSONLæ ¼å¼ï¼Œæœ‰é…å¯¹)
  - dialogue_data.json (10000æ¡ï¼ŒJSONLæ ¼å¼ï¼Œæœ‰é…å¯¹)
  - general_data.json (4507æ¡ï¼ŒJSONLæ ¼å¼ï¼Œâš ï¸å™ªå£°ä¸¥é‡)
  - summarization_data.json (JSONLæ ¼å¼)
```

### è¾“å‡ºæ–‡ä»¶
```
/workspace/multiobjective_llama/<RUN_ID>/
  - train_step_metrics.csv (é€æ­¥æŒ‡æ ‡)
  - train_step_metrics.jsonl (å¤‡ç”¨)
  - training_metrics_summary.json (æœ€ç»ˆæ±‡æ€»)
```

---

## ğŸ”¬ è¯Šæ–­æ–¹æ³•

### å¿«é€Ÿæ£€æŸ¥æ¸…å•ï¼ˆè®­ç»ƒå‰ï¼‰
```bash
# 1. ç¡®è®¤é…ç½®å·²æ›´æ–°
grep "MIN_NEW_TOKENS_TRAIN = 5" grpo-dual/src/grpo/trainer.py
grep "template_phrases = \[" grpo-dual/src/grpo/trainer.py

# 2. æ£€æŸ¥gitçŠ¶æ€
git log -1 --oneline
# åº”è¯¥çœ‹åˆ°: f140a1c Fix entropy collapse...

# 3. ç¡®è®¤åœ¨æ­£ç¡®åˆ†æ”¯
git branch --show-current
# åº”è¯¥æ˜¯: claude/open-trainer-py-011CUp9RqkPbRBQPMVzBRuJ3
```

### è®­ç»ƒä¸­è§‚å¯Ÿï¼ˆå‰20æ­¥ï¼‰
å…³æ³¨ç»ˆç«¯è¾“å‡ºä¸­çš„ï¼š
1. **Fairnessè¯Šæ–­æ¨¡å—** - ç†µå€¼ã€ç”Ÿæˆé•¿åº¦ã€ç”Ÿæˆå†…å®¹
2. **Reward Scaleè¯Šæ–­** - ä¿¡å·å¼ºåº¦ã€stdã€EMAæ¯”å€¼
3. **Judge provideråˆ†å¸ƒ** - template_detectorå‡ºç°é¢‘ç‡
4. **é•¿åº¦æƒ©ç½šç»Ÿè®¡** - å¤šå°‘æ ·æœ¬è¢«æƒ©ç½š

### è®­ç»ƒååˆ†æï¼ˆ50æ­¥+ï¼‰
```bash
# æŸ¥çœ‹CSVï¼ˆæ¨èç”¨pandasï¼‰
import pandas as pd
df = pd.read_csv("/workspace/multiobjective_llama/<RUN_ID>/train_step_metrics.csv")

# å…³é”®åˆ—
df[['step', 'kl_f', 'kl_h', 'reward_f_mean', 'reward_h_mean',
    'clip_frac', 'gen_len_f_mean', 'gen_len_h_mean',
    'trunc_frac_f', 'trunc_frac_h']].head(20)

# ç»˜åˆ¶è¶‹åŠ¿
import matplotlib.pyplot as plt
fig, axes = plt.subplots(2, 2, figsize=(12, 8))
df.plot(x='step', y='reward_f_mean', ax=axes[0,0], title='Fairness Reward')
df.plot(x='step', y='reward_h_mean', ax=axes[0,1], title='Hallucination Reward')
df.plot(x='step', y='gen_len_f_mean', ax=axes[1,0], title='Fairness Length')
df.plot(x='step', y='gen_len_h_mean', ax=axes[1,1], title='Hallucination Length')
plt.tight_layout()
plt.savefig('training_trends.png')
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### Piä¸“å®¶çš„åˆ†æè¦ç‚¹

#### BBQæ•°æ®é›†ï¼ˆå·²éªŒè¯æ— é—®é¢˜ï¼‰
- âœ… ç»“æ„è‰¯å¥½ï¼Œæ ‡æ³¨ä¸€è‡´
- âœ… Ambiguous/Disambiguatedè®¾è®¡æ­£ç¡®
- âœ… æ ‡ç­¾åˆ†å¸ƒå‡è¡¡ï¼ˆå„é€‰é¡¹ã€å„ææ€§éƒ½æˆå¯¹å‡ºç°ï¼‰
- âš ï¸ Unknowné€‰é¡¹ä½ç½®æ˜¯åŠ¨æ€çš„ï¼ˆå¿…é¡»ç”¨answer_infoåˆ¤å®šï¼‰

#### HaluEvalæ•°æ®é›†
**Generalå­é›†é—®é¢˜ï¼š**
- "å¹»è§‰"æ¦‚å¿µæ··ç”¨ï¼ˆäº‹å®é”™è¯¯+ä¸å®Œæ•´+èƒ½åŠ›å£°æ˜+æ ¼å¼é—®é¢˜ï¼‰
- çº¦815ä¸ªyesæ ‡æ³¨ï¼Œå…¶ä¸­13ä¸ªspansä¸ºç©º
- çº¦200+ä¸ª"As an AI..."è¢«æ ‡ä¸ºå¹»è§‰
- ç»“è®ºï¼šéœ€è¦è¿‡æ»¤ï¼Œåªä¿ç•™æ˜ç¡®äº‹å®é”™è¯¯

**Dialogueå­é›†ï¼ˆè´¨é‡å¥½ï¼‰ï¼š**
- âœ… æˆå¯¹æ ‡æ³¨ï¼ˆright vs hallucinatedï¼‰
- âœ… åŸºäºknowledgeçš„ä¸€è‡´æ€§
- âœ… åªæœ‰è½»å¾®å™ªå£°

**QAå­é›†ï¼ˆè´¨é‡å¥½ï¼‰ï¼š**
- âœ… æˆå¯¹æ ‡æ³¨
- âœ… æ¸…æ™°çš„äº‹å®ä¾æ®

### ç®—æ³•å‚è€ƒ

#### BAPO (Balanced Advantage Policy Optimization)
- åŠ¨æ€è°ƒæ•´PPOè£å‰ªè¾¹ç•Œï¼ˆä¸å¯¹ç§°ï¼‰
- c_low: 0.6â†’0.9, c_high: 1.2â†’3.0
- ç›®æ ‡ï¼šå¹³è¡¡positive/negativeæ ·æœ¬çš„æ¢¯åº¦è´¡çŒ®
- é€‚ç”¨åœºæ™¯ï¼šé˜²æ­¢ç†µå¡Œé™·ï¼Œé¼“åŠ±æ¢ç´¢

#### DAPO (Decoupled Clip and Dynamic Sampling Policy Optimization)
- Clip-Higher: ä¸Šç•Œä»1.2â†’1.28
- Dynamic Sampling: è¿‡æ»¤accuracy=1æˆ–0çš„promptç»„
- Token-Level Loss: å¯¹æ‰€æœ‰tokenèšåˆ
- Overlong Reward Shaping: æƒ©ç½šè¶…é•¿å›ç­”

---

## ğŸš€ ä¸‹ä¸€æ­¥è®¡åˆ’

### çŸ­æœŸï¼ˆä»Šå¤©ï¼‰
1. âœ… ç”¨A+Bä¿®å¤çš„ä»£ç è·‘50æ­¥
2. âœ… è§‚å¯Ÿå‰20æ­¥è¯Šæ–­è¾“å‡º
3. âœ… æ ¹æ®ç»“æœå†³å®šæ˜¯å¦éœ€è¦Plan B

### ä¸­æœŸï¼ˆå¦‚æœA+BæˆåŠŸï¼‰
1. ç»§ç»­è®­ç»ƒåˆ°100-200æ­¥
2. è§‚å¯Ÿæ”¶æ•›æƒ…å†µ
3. è¯„ä¼°Paretoå‰æ²¿

### ä¸­æœŸï¼ˆå¦‚æœéœ€è¦Plan Bï¼‰
1. æ ¹æ®å†³ç­–æ ‘é€‰æ‹©å¯¹åº”æ–¹æ¡ˆ
2. å®æ–½ä¿®å¤
3. é‡æ–°è®­ç»ƒ50æ­¥éªŒè¯

### é•¿æœŸï¼ˆä¼˜åŒ–æ–¹å‘ï¼‰
1. å®æ–½HaluEvalé…å¯¹å¯¹æ¯”å­¦ä¹ ï¼ˆPlan B2ï¼‰
2. è€ƒè™‘BAPO/DAPOæŠ€æœ¯ï¼ˆä¸å¯¹ç§°è£å‰ªã€åŠ¨æ€é‡‡æ ·ï¼‰
3. å¢åŠ Best-of-Næˆ–Rejection Sampling

---

## âš ï¸ å·²çŸ¥é™åˆ¶å’Œæ³¨æ„äº‹é¡¹

### ç¯å¢ƒ
- GPUæ˜¾å­˜é™åˆ¶ï¼šå·²é™ä½batch sizeå’ŒLoRA rank
- APIé…é¢ï¼šOpenAI + ClaudeåŒäº‘ï¼Œæœ‰heuristicå…œåº•
- ç½‘ç»œç¨³å®šæ€§ï¼šå·²å®ç°é‡è¯•å’ŒæŒ‡æ•°é€€é¿

### æ•°æ®
- BBQåªç”¨äº†2ä¸ªç±»åˆ«ï¼ˆGender, Disabilityï¼‰ï¼Œè¿˜æœ‰9ä¸ªç±»åˆ«æœªç”¨
- HaluEvalçš„generalå­é›†å™ªå£°éœ€è¦å¤„ç†
- é…å¯¹æ ·æœ¬æœªå……åˆ†åˆ©ç”¨

### è®­ç»ƒ
- SFT targetå¯èƒ½ä¸RLé˜¶æ®µçš„æ¨¡æ¿æ£€æµ‹å™¨æœ‰è½»å¾®å†²çªï¼ˆambiguousæ ·æœ¬ï¼‰
- Tokenizationå¯èƒ½æˆªæ–­é•¿contextï¼ˆå¾…éªŒè¯ï¼‰
- KLæ§åˆ¶çš„Î²å€¼å¯èƒ½éœ€è¦æ ¹æ®è®­ç»ƒè¿›åº¦è°ƒæ•´

---

## ğŸ“ äº¤æ¥æ£€æŸ¥ç‚¹

æ¥æ‰‹æ­¤é¡¹ç›®çš„äººåº”è¯¥èƒ½å¤Ÿï¼š

### å¿…éœ€äº†è§£
1. âœ… ç†µå¡Œé™·é—®é¢˜çš„æ ¹æœ¬åŸå› å’Œä¿®å¤æ–¹æ¡ˆ
2. âœ… BBQæ•°æ®é›†çš„æ­£ç¡®ä½¿ç”¨æ–¹å¼ï¼ˆåŠ¨æ€unknownï¼‰
3. âœ… HaluEvalæ•°æ®é›†çš„é—®é¢˜å’Œæ½œåœ¨ä¿®å¤æ–¹æ¡ˆ
4. âœ… å¦‚ä½•è§£è¯»è®­ç»ƒæ—¥å¿—ï¼ˆç†µã€æ¢¯åº¦ä¿¡å·ã€provideråˆ†å¸ƒï¼‰

### å¿…éœ€æŒæ¡
1. âœ… è¿è¡Œè®­ç»ƒå¹¶è§‚å¯Ÿå‰20æ­¥
2. âœ… æ ¹æ®å†³ç­–æ ‘é€‰æ‹©å¯¹åº”çš„Plan B
3. âœ… ä¿®æ”¹ä»£ç å®æ–½Plan Bï¼ˆå¦‚æœéœ€è¦ï¼‰
4. âœ… åˆ†æCSVæ–‡ä»¶å’Œç»˜åˆ¶è¶‹åŠ¿å›¾

### å¯é€‰æŠ€èƒ½
1. BAPO/DAPOç®—æ³•çš„å®ç°
2. Paretoå‰æ²¿ä¼˜åŒ–
3. æ›´å¤æ‚çš„reward shaping

---

## ğŸ“ æ›´æ–°æ—¥å¿—

**2025-11-08 (Session 1):**
- âœ… å®ŒæˆA+Bä¿®å¤ï¼ˆMIN_NEW_TOKENSé™ä½ + æ¨¡æ¿æ£€æµ‹å™¨ï¼‰
- âœ… Commit f140a1cæ¨é€åˆ°è¿œç¨‹åˆ†æ”¯
- âœ… æ•´ç†Piä¸“å®¶çš„æ•°æ®é›†åˆ†æ
- âœ… æ·»åŠ C2ç›‘æ§ï¼ˆé›¶æ¢¯åº¦ç»„æ£€æµ‹ï¼‰
- âœ… Commit 7294249æ¨é€ï¼ˆC2ç›‘æ§ + HANDOFFåˆ›å»ºï¼‰

**2025-11-08 (Session 2 - å½“å‰):**
- âœ… æ¥æ”¶Piä¸“å®¶çš„è®­ç»ƒæ—¥å¿—è¯Šæ–­ï¼ˆ6ç‚¹æ€»ç»“ï¼‰
- âœ… **å®æ–½Plan Cå…¨é¢ä¿®å¤ï¼š**
  - âœ… ä¿®æ”¹compute_group_advantagesï¼ˆé¿å…æ¢¯åº¦æŠ¹å¹³ï¼‰
  - âœ… å¢å¼ºç†µæ­£åˆ™åŒ–ï¼ˆENTROPY_COEF: 0.5â†’2.0ï¼‰
  - âœ… é™ä½KLçº¦æŸï¼ˆbeta: 0.30â†’0.05ï¼‰
  - âœ… å¢å¼ºæ¨¡æ¿æ£€æµ‹å™¨ï¼ˆ13ç§çŸ­è¯­ï¼Œæ›´å¤§æƒ©ç½šï¼‰
- âœ… Commit f3f5c7dæ¨é€ï¼ˆPlan Cå…¨é¢ä¿®å¤ï¼‰
- ğŸ” **å‘ç°å·¥ç¨‹æ ¹æœ¬é—®é¢˜ï¼šæ‰¹é‡ç”Ÿæˆå¯¼è‡´Kä¸ªå€™é€‰ç›¸åŒ**
- âœ… **å®æ–½ä¸²è¡Œç”Ÿæˆä¿®å¤ï¼ˆé—®é¢˜4ï¼‰ï¼š**
  - âœ… å®Œå…¨é‡å†™generate_candidates_batchä¸ºä¸²è¡Œæ¨¡å¼
  - âœ… æ¯ä¸ªpromptç‹¬ç«‹ç”Ÿæˆkæ¬¡ï¼Œç¡®ä¿random stateå˜åŒ–
  - âœ… ç›´æ¥è§£å†³"åŒç»„rewardç›¸åŒâ†’std=0â†’æ— æ¢¯åº¦"
- âœ… æ›´æ–°HANDOFF.mdï¼ˆè®°å½•ä¸²è¡Œç”Ÿæˆä¿®å¤ï¼‰
- âœ… Commit 9a6f525æ¨é€ï¼ˆä¸²è¡Œç”Ÿæˆä¿®å¤ï¼‰
- âœ… åˆ›å»ºtest_serial_generation.pyå®éªŒè„šæœ¬
- âœ… Commit 5c5e710æ¨é€ï¼ˆå®éªŒè„šæœ¬ï¼‰
- ğŸ§ª **è¿è¡ŒInstruct modelå®éªŒéªŒè¯ä¸²è¡Œç”Ÿæˆæ•ˆæœï¼š**
  - âœ… ä¸²è¡Œç”Ÿæˆç¡®å®äº§ç”Ÿå­—é¢å·®å¼‚ï¼ˆ4/4å”¯ä¸€ï¼‰
  - âš ï¸ ä½†ç†µä»æä½ï¼ˆ0.2-0.4ï¼‰ï¼Œå®è´¨å†…å®¹é«˜åº¦ç›¸ä¼¼
  - âš ï¸ ç®€å•é—®é¢˜ä¸Š4ä¸ªå€™é€‰éƒ½é€‰å¯¹ â†’ rewardç›¸åŒ â†’ std=0
- ğŸ§ª **Base modelå®éªŒï¼ˆå¤±è´¥ï¼‰ï¼š**
  - ğŸ’¡ å‡è®¾ï¼šBase modelæ²¡æœ‰è¿‡å¼ºå…ˆéªŒï¼Œæ›´å®¹æ˜“äº§ç”Ÿå¤šæ ·æ€§
  - âœ… åˆ›å»ºtest_base_model.pyå¹¶è¿è¡Œå®éªŒ
  - âŒ ç»“æœï¼šBase modelè¾“å‡ºä¹±ç ï¼Œå®Œå…¨ä¸ç†è§£æ ¼å¼
  - âŒ ç†µä»ç„¶ä½ï¼ˆ0.27-0.52ï¼‰ï¼Œä¸”å†…å®¹ä¸å¯ç”¨
  - ğŸ’¡ **å†³ç­–ï¼šå›åˆ°Instruct modelï¼Œæ”¹è¿›Judgeè¯„åˆ†**
- âœ… **å®æ–½Option Aï¼šæ”¹è¿›Judgeäº§ç”Ÿåˆ†æ•°å·®å¼‚ï¼ˆé—®é¢˜5ï¼‰ï¼š**
  - âœ… å›åˆ°Instruct modelï¼ˆBASE_MODEL: Meta-Llama-3-8B-Instructï¼‰
  - âœ… æ”¹è¿›BBQ Judgeè¯„åˆ†ï¼Œä¸åªçœ‹ç­”æ¡ˆæ­£ç¡®æ€§ï¼Œè¿˜è¯„ä¼°reasoningè´¨é‡
  - âœ… æ·»åŠ _assess_reasoning_quality()æ–¹æ³•ï¼ˆå¼•ç”¨contextã€é•¿åº¦ã€æ¨¡æ¿åŒ–ï¼‰
  - âœ… åˆ†æ•°ä»äºŒå…ƒï¼ˆ1.0/-1.0ï¼‰å˜ä¸ºå¤šçº§ï¼ˆ1.0/0.7/0.5ï¼‰
  - âœ… åˆ›å»ºtest_improved_judge.pyéªŒè¯
  - âœ… å®éªŒç»“æœï¼šscores=[0.70, 1.00, 1.00, 0.70], std=0.15 âœ…
- âœ… Commit e51938bæ¨é€ï¼ˆOption A: Improve Judge scoringï¼‰
- âœ… Commit bb009a5æ¨é€ï¼ˆUpdate HANDOFF.mdï¼‰

**2025-11-08 (Session 3 - æ¿€è¿›ä¿®å¤):**
- ğŸ”¥ **ç”¨æˆ·åé¦ˆï¼š"è¿™çœŸçš„æ˜¯æ–°æ—¥å¿—"** - å‰é¢ä¿®å¤ä»ä¸å¤Ÿï¼Œé—®é¢˜ä¾ç„¶å­˜åœ¨
- ğŸ” **ç”¨æˆ·æä¾›è¯¦ç»†è¯Šæ–­ï¼ˆç›´æ¥ç¿»è¯‘ç‰ˆï¼‰ï¼š**
  - ç†µå¡Œé™·ä¸¥é‡ï¼ˆ0.017-0.055ï¼Œæä½ï¼‰
  - Reward std=0ï¼ˆæ‰€æœ‰candidateså¾—åˆ†ç›¸åŒï¼‰
  - æ¨¡å‹è¾“å‡ºæ¨¡æ¿åŒ–ï¼š"The context does not provide sufficient information"
  - >50%ç»„æ— æ¢¯åº¦
  - æ ¸å¿ƒé—®é¢˜ï¼š"æ¨¡å‹å­¦ä¼šç”¨å•ä¸€ã€å®‰å…¨æ¨¡æ¿ç³Šå¼„æ‰€æœ‰probe â†’ rewardå¸¸æ•° â†’ RLæ— æ³•å­¦ä¹ "
- ğŸ¯ **ç”¨æˆ·å»ºè®®5å¤§æªæ–½ï¼š**
  1. å¢åŠ å€™é€‰å¤šæ ·æ€§ï¼ˆå»é‡ã€é‡é‡‡ï¼‰
  2. å¤šçº§rewardï¼ˆä¸åª1.0/-0.7ä¸¤æ¡£ï¼‰
  3. å¯¹æ¨¡æ¿å¼è¾“å‡ºç›´æ¥è´Ÿå¥–åŠ±
  4. æ”¾å®½é‡‡æ ·å‚æ•°ï¼ˆtop-p, temperatureï¼‰
  5. ç²¾ç»†åŒ–rewardè®¾è®¡
- âœ… **å®æ–½æ¿€è¿›ä¿®å¤ï¼ˆæ ¸é€‰é¡¹ï¼‰ï¼š**
  - âœ… è¶…ä¸¥æ ¼reasoning qualityè¯„ä¼°ï¼ˆæ£€æµ‹13ç§é€ƒé¿çŸ­è¯­â†’-0.5ï¼Œå®ä½“å¼•ç”¨ï¼Œé•¿åº¦10-40è¯ï¼Œæ¨¡æ¿çŸ­è¯­1æ¬¡æ‰£åˆ†ï¼Œè¯æ±‡é‡å¤åº¦æ£€æŸ¥ï¼‰
  - âœ… Jaccardå»é‡æœºåˆ¶ï¼ˆç›¸ä¼¼åº¦>0.65â†’ä¸¢å¼ƒé‡é‡‡ï¼Œæœ€å¤š3æ¬¡é‡è¯•ï¼‰
  - âœ… æ¿€è¿›é‡‡æ ·å‚æ•°ï¼ˆtemp=1.1, top_k=150, top_p=0.95, rep_penalty=1.25ï¼‰
  - âœ… åˆ›å»ºtest_aggressive_judge.pyéªŒè¯
- âœ… Commit 5495a32æ¨é€ï¼ˆAGGRESSIVE FIX: all user-recommended measuresï¼‰
- ğŸ“Š **é¢„æœŸæ•ˆæœï¼š**
  - Candidateså¿…é¡»35%+ä¸åŒï¼ˆJaccard<0.65ï¼‰å¦åˆ™é‡é‡‡
  - æ¨¡æ¿è¾“å‡ºå¾—-0.5è‡³-1.0æƒ©ç½š
  - å³ä½¿æ­£ç¡®ç­”æ¡ˆï¼Œæ ¹æ®reasoningè´¨é‡å¾—åˆ†0.3-1.0
  - åº”äº§ç”Ÿreward_std>0.1ï¼Œå³ä½¿åœ¨ç®€å•é—®é¢˜ä¸Š
  - **å¦‚æœè¿™è¿˜ä¸è¡Œï¼Œæ ¹å› ä¸åœ¨Judge/é‡‡æ ·ï¼Œéœ€è¦é‡æ–°å®¡è§†æ¶æ„**
- ğŸ”¥ **ç”¨æˆ·å†æ¬¡åé¦ˆï¼šä»ç„¶100%ç»„æ— æ¢¯åº¦ï¼Œå‘ç°æ ¹æœ¬åŸå› **
- ğŸ¯ **ç”¨æˆ·è¯Šæ–­æ ¸å¿ƒé—®é¢˜ï¼ˆMode Collapseï¼‰ï¼š**
  - Max prob: 0.999988ï¼ˆå‡ ä¹deterministicï¼‰
  - ç†µ: 0.018-0.055ï¼ˆç¾éš¾æ€§ä½ï¼‰
  - 100%ç»„reward std=0ï¼ˆé›¶æ¢¯åº¦ï¼‰
  - å»é‡å¤±è´¥ï¼š3æ¬¡é‡è¯•åä»Jaccard>0.75
  - EOSæŠ‘åˆ¶å™¨ä¸€ç›´åœ¨é˜»æ­¢early stopping
  - æ¨¡å‹åœ¨ç”Ÿæˆ1-3ä¸ªtokenæ—¶å°±æƒ³åœæ­¢
- ğŸ’¡ **æ ¹æœ¬åŸå› ï¼šLogitsè£å‰ªå‘ç”Ÿåœ¨temperatureä¹‹å‰ï¼**
  - SanityLogitsProcessor: `scores.clamp(-50, 50)`
  - Flow: raw_logits â†’ clip(-50,50) â†’ /temp â†’ softmax
  - å³ä½¿temp=1.1ï¼Œsoftmax(50/1.1)â‰ˆsoftmax(45.5)â‰ˆ0.9999+
  - **Temperatureæ ¹æœ¬æ²¡æœ‰ç”Ÿæ•ˆï¼**
- âœ… **æ ¸é€‰é¡¹ä¿®å¤ï¼ˆçœŸæ­£è§£å†³æ ¹å› ï¼‰ï¼š**
  - âœ… ç¦ç”¨logitsè£å‰ªï¼ˆ-50,50 â†’ -1000,1000ï¼‰ï¼Œåªé˜²æº¢å‡ºä¸é™åˆ¶åˆ†å¸ƒ
  - âœ… Temperatureæå‡åˆ°2.0ï¼ˆå¯¹æŠ—Llama-3-Instructé«˜ç½®ä¿¡åº¦ï¼‰
  - âœ… è¿›ä¸€æ­¥æ”¾æ¾é‡‡æ ·ï¼ˆtop_k=200, top_p=0.98, rep_penalty=1.3ï¼‰
- âœ… Commit b812b25æ¨é€ï¼ˆNUCLEAR OPTION: Fix logits clippingï¼‰
- ğŸ“Š **é¢„æœŸæ•ˆæœï¼ˆæ ¸é€‰é¡¹ï¼‰ï¼š**
  - Max probåº”é™è‡³<0.95ï¼ˆç°åœ¨0.999988ï¼‰
  - ç†µåº”å‡è‡³>0.5ï¼ˆç°åœ¨0.018-0.055ï¼‰
  - å»é‡åº”æˆåŠŸï¼ˆJaccard<0.65ï¼‰
  - Reward stdåº”>0.05ï¼ˆç°åœ¨0.000000ï¼‰
  - éé›¶æ¢¯åº¦ç»„åº”>50%ï¼ˆç°åœ¨0%ï¼‰
  - **å¦‚æœè¿™è¿˜ä¸è¡Œï¼Œé—®é¢˜åœ¨SFTé˜¶æ®µæ¨¡æ¿å¤ªå¼º/LoRAå¤ªå¼±/éœ€å…¨é‡å¾®è°ƒ**

**2025-11-08 (Session 4 - æ ¸é€‰é¡¹éªŒè¯ & å¹³è¡¡è°ƒæ•´):**
- ğŸ‰ **æ ¸é€‰é¡¹æˆåŠŸï¼ç†µå®Œå…¨æ¢å¤ï¼š**
  - âœ… Entropy: mean=3.7-5.1, min=2.2-5.0 (ä¿®å¤å‰: mean=0.033, min=0.018)
  - âœ… Logits clippingç¦ç”¨ + Temperature=2.0æˆåŠŸå¯¹æŠ—Instructæ¨¡å‹é«˜ç½®ä¿¡åº¦
  - âœ… Reward varianceå¼€å§‹å‡ºç°ï¼šStep3 F:std=0.280, Step4-5 F:std=0.700
- âš ï¸ **æ–°é—®é¢˜ï¼š100%æˆªæ–­ç‡**
  - Step3-6å‡ ä¹æ‰€æœ‰æ ·æœ¬è¾¾åˆ°max_new_tokens=128ç¡¬çº¦æŸ
  - åŸå› ï¼štemp=2.0å¤ªé«˜ + no_repeat_ngram_size=3å¤ªä¸¥ â†’ å¼ºåˆ¶ç”Ÿæˆé•¿å›ç­”
- âœ… **å¹³è¡¡è°ƒæ•´ï¼ˆCommit d3648c8ï¼‰ï¼š**
  - Temperature: 2.0 â†’ 1.5ï¼ˆEntropy=4.7å·²è¶³å¤Ÿï¼Œé™æ¸©æ§åˆ¶é•¿åº¦ï¼‰
  - no_repeat_ngram_size: 3 â†’ 0ï¼ˆç¦ç”¨3-gramçº¦æŸï¼Œå¤ªä¸¥æ ¼ï¼‰
  - ä¿ç•™presence_penalty=0.7å’Œfrequency_penalty=0.3
- âš ï¸ **å‰©ä½™é—®é¢˜ï¼š50%ç»„ä»é›¶æ¢¯åº¦**
  - Step1: 100%ç»„æ— æ¢¯åº¦ â†’ Step2,4,6: 50%ç»„æ— æ¢¯åº¦ï¼ˆæœ‰æ”¹å–„ä½†ä¸å¤Ÿï¼‰
  - ä»providerç»Ÿè®¡çœ‹ï¼š`template_detector=2/8`ä»åœ¨è§¦å‘
  - æ¨æµ‹ï¼šæ¨¡å‹ç”¨ä¸åŒè¡¨è¾¾æ–¹å¼è¯´ç›¸åŒé€ƒé¿å†…å®¹ï¼ˆé«˜ç†µä½†åŒä¹‰ï¼‰
- ğŸ” **æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼ˆCommit 3d88b09ï¼‰ï¼š**
  - åœ¨Step 1-3æ‰“å°è§¦å‘template_detectorçš„æ ·æœ¬è¯¦æƒ…
  - æ˜¾ç¤ºåŒ¹é…çš„çŸ­è¯­ã€promptã€responseå‰æ®µ
  - ç”¨äºè¯Šæ–­ï¼šé€ƒé¿çŸ­è¯­å˜ä½“ï¼Ÿreasoning qualityè¯„åˆ†æœ‰æ•ˆæ€§ï¼Ÿ
- ğŸ“Š **ç”¨æˆ·ç²¾ç®€æ—¥å¿—ï¼ˆCommit f4fef4eï¼‰ï¼š**
  - æ—¥å¿—ä»~200è¡Œ/stepå‹ç¼©åˆ°~10è¡Œ/step
  - ä¿ç•™æ ¸å¿ƒè­¦å‘Šï¼šç†µå¡Œé™·ã€é›¶æ¢¯åº¦ã€ä¸¥é‡å¤±è¡¡
  - åˆ é™¤ï¼šEOS Suppressorè¯¦æƒ…ã€ä¸²è¡Œç”Ÿæˆæ—¥å¿—ã€æ¯æ ·æœ¬Fairnessè¯Šæ–­

**2025-11-08 (Session 5 - æ·±å…¥è¯Šæ–­é›¶æ¢¯åº¦ç»„):**
- ğŸ“Š **ç”¨æˆ·è¿è¡Œè®­ç»ƒååé¦ˆï¼Œè¯Šæ–­ç»“æœï¼š**
  - âœ… ç†µæ”¹å–„ï¼šmean=2.3-4.3ï¼ˆè™½ç„¶minä»æœ‰0.028-0.037ä½å€¼ç‚¹ï¼‰
  - âœ… æˆªæ–­ç‡é™ä½ï¼šä»100%é™åˆ°50-75%ï¼ˆTemperature=1.5ç”Ÿæ•ˆï¼‰
  - âš ï¸ ä»æœ‰50%ç»„é›¶æ¢¯åº¦ï¼ˆStep 1,2,3,5,6éƒ½æ˜¯50%ï¼ŒStep 4æ˜¯100%ï¼‰
- ğŸ” **Template Detectorè°ƒè¯•æ—¥å¿—æ­ç¤ºï¼š**
  - **æ‰€æœ‰è§¦å‘çš„æ ·æœ¬éƒ½æ˜¯ambigï¼**ï¼ˆContext condition: ambigï¼‰
  - åŒ¹é…çŸ­è¯­ï¼š"does not provide sufficient information", "cannot be determined"
  - **è¿™æ˜¯æ­£ç¡®è¡Œä¸ºï¼** Ambiguousæ ·æœ¬æœ¬æ¥å°±è¯¥ç­”"cannot determine"
  - ä»£ç ç»™äº†-0.2è½»å¾®è´Ÿåˆ†ï¼ˆä¸æ˜¯-1.0é‡ç½šï¼‰ï¼Œç¬¦åˆè®¾è®¡
  - **ç»“è®ºï¼šTemplate detectorå·¥ä½œæ­£å¸¸ï¼Œä¸æ˜¯é›¶æ¢¯åº¦æ ¹æº**
- ğŸ¯ **çœŸæ­£é—®é¢˜å®šä½ï¼šbbq_ruleç»™ç›¸åŒåˆ†æ•°**
  - Providerç»Ÿè®¡ï¼š`{'template_detector': 1, 'bbq_rule': 3, 'halueval_rule': 4}`
  - Fairness 4ä¸ªæ ·æœ¬ï¼š1ä¸ªambigï¼ˆtemplate_detectorï¼‰ï¼Œ3ä¸ªdisambigï¼ˆbbq_ruleï¼‰
  - **è¿™3ä¸ªdisambigæ ·æœ¬èµ°bbq_rule â†’ reward std=0.000**
  - **æ¨æµ‹ï¼š** æ‰€æœ‰candidatesé€‰äº†æ­£ç¡®ç­”æ¡ˆï¼Œä½†reasoning qualityè¯„åˆ†æœªåŒºåˆ†å‡ºå·®å¼‚
- ğŸ”§ **æ·»åŠ é›¶æ¢¯åº¦ç»„è¯¦ç»†è¯Šæ–­ï¼ˆCommit 33d492aï¼‰ï¼š**
  - Step 1-3æ‰“å°ç¬¬ä¸€ä¸ªé›¶æ¢¯åº¦ç»„çš„4ä¸ªcandidatesè¯¦æƒ…
  - é‡æ–°è°ƒç”¨bbq_ruleè¯„ä¼°ï¼Œæ˜¾ç¤ºæ¯ä¸ªcandidateçš„reasoning qualityåˆ†æ•°
  - å°†æ­ç¤ºï¼š
    * 4ä¸ªcandidatesæ˜¯å¦é€‰äº†ç›¸åŒç­”æ¡ˆï¼ˆé¢„æœŸï¼‰
    * Reasoning qualityåˆ†æ•°æ˜¯å¦æœ‰å·®å¼‚ï¼ˆæœŸæœ›0.3-1.0èŒƒå›´ï¼‰
    * `_assess_reasoning_quality()`æ˜¯å¦åœ¨å·¥ä½œ
    * è¿˜æ˜¯4ä¸ªcandidatesçš„reasoningå®Œå…¨ç›¸åŒï¼Ÿ

**2025-11-08 (Session 5 ç»­ - ğŸ¯æ‰¾åˆ°æ ¹æœ¬åŸå› å¹¶ä¿®å¤):**
- ğŸ” **é›¶æ¢¯åº¦ç»„è¯Šæ–­ç»“æœåˆ†æï¼š**
  - **æ‰€æœ‰é›¶æ¢¯åº¦ç»„éƒ½æ˜¯ambigæ ·æœ¬ï¼**
  - Step 1ç»„0ï¼š4ä¸ªcandidateså…¨æ˜¯`Reward: -1.000`ï¼ˆcontext_condition: ambigï¼‰
  - Step 2ç»„1ï¼š4ä¸ªcandidateså…¨æ˜¯`Reward: -1.000`ï¼ˆcontext_condition: ambigï¼‰
  - ä½†æ˜¯ä»£ç Line 1748æ˜æ˜å†™çš„æ˜¯è¿”å›-0.2ï¼Œä¸ºä»€ä¹ˆå˜æˆ-1.0ï¼Ÿ

- ğŸ› **Bug #1ï¼šRewardæ˜ å°„é€»è¾‘é”™è¯¯ï¼ˆLine 2919ï¼‰**
  ```python
  # é”™è¯¯ä»£ç ï¼š
  r = max(0.0, min(1.0, float(r))) * 2 - 1
  ```
  - **å‡è®¾ï¼š** judgeè¿”å›[0, 1]ï¼Œæ˜ å°„åˆ°[-1, 1]
  - **ç°å®ï¼š** æ‰€æœ‰judgeéƒ½è¿”å›[-1, 1]ï¼
  - **åæœï¼š** template_detectorè¿”å›-0.2 â†’ `max(0.0, -0.2)` = 0.0 â†’ `0.0*2-1` = **-1.0**
  - **ç»“æœï¼š** æ‰€æœ‰è´Ÿåˆ†éƒ½è¢«æˆªæ–­å¹¶æ˜ å°„åˆ°-1.0 â†’ std=0 â†’ é›¶æ¢¯åº¦ï¼

- ğŸ› **Bug #2ï¼šAmbigæ ·æœ¬ç»™å›ºå®šåˆ†æ•°ï¼ˆLine 1507ï¼‰**
  - Template_detectorç»™ambigæ ·æœ¬-0.2ï¼ˆå›ºå®šåˆ†ï¼‰
  - æˆ–bbq_ruleç»™ambigæ ·æœ¬1.0/-1.0ï¼ˆæ— reasoningè´¨é‡å·®å¼‚ï¼‰
  - 4ä¸ªcandidateséƒ½è§¦å‘templateçŸ­è¯­ â†’ éƒ½æ˜¯-0.2 â†’ æ˜ å°„åéƒ½æ˜¯-1.0 â†’ std=0

- âœ… **ä¿®å¤æ–¹æ¡ˆï¼ˆCommit 2e08b17ï¼‰ï¼š**

  **Fix #1: ç§»é™¤é”™è¯¯çš„rewardæ˜ å°„**
  ```python
  # Line 2919-2921
  r = r_obj.get("final", 0.0)
  # ã€ä¿®å¤ã€‘ç›´æ¥ä½¿ç”¨judgeè¿”å›çš„[-1, 1]åˆ†æ•°ï¼Œä¸åšæ˜ å°„
  return float(np.clip(r, -config.REWARD_CLIP, config.REWARD_CLIP))
  ```

  **Fix #2: Ambigæ ·æœ¬è¯„ä¼°reasoningè´¨é‡**
  ```python
  # Line 1741-1743: Ambigæ ·æœ¬è·³è¿‡template_detector
  if sample.task == "fairness" and context_condition == "ambig":
      pass  # ä¸æ‹¦æˆªï¼Œç»§ç»­èµ°åˆ°bbq_rule

  # Line 1507-1537: Bbq_ruleå¯¹ambigæ ·æœ¬è¯„ä¼°reasoningè´¨é‡
  if chosen_answer == unknown_option:
      score = 1.0
      # æ ¹æ®justificationé•¿åº¦ï¼ˆ8-50è¯ï¼‰ã€é‡å¤åº¦è°ƒæ•´
      score = max(0.3, min(1.0, score))  # [0.3, 1.0]èŒƒå›´
  ```

- ğŸ¯ **é¢„æœŸæ•ˆæœï¼š**
  - Ambigæ ·æœ¬ï¼š4ä¸ªcandidateså¾—åˆ°å·®å¼‚åŒ–çš„åˆ†æ•°ï¼ˆ0.3-1.0ï¼‰
  - Disambigæ ·æœ¬ï¼šä¿ç•™ç°æœ‰é€»è¾‘ï¼ˆæ­£ç¡®ç­”æ¡ˆ + reasoningè´¨é‡ï¼‰
  - é›¶æ¢¯åº¦ç»„æ¯”ä¾‹åº”å¤§å¹…ä¸‹é™ï¼ˆä»50-100% â†’ <20%ï¼‰
  - Reward stdåº”æ˜¾è‘—æå‡

**2025-11-08 (Session 5 ç»­2 - éªŒè¯ä¿®å¤å¹¶å‘ç°HaluEvalé—®é¢˜):**
- âœ… **Ambigæ ·æœ¬ä¿®å¤éªŒè¯æˆåŠŸï¼**
  - Step 2: `F: std=0.680` (ä¹‹å‰æ˜¯0.000)
  - Step 5: `F: std=0.770` (æœ‰æ˜æ˜¾åˆ†æ•°å·®å¼‚)
  - Template detectorä»è§¦å‘ambigæ ·æœ¬ï¼Œä½†ç°åœ¨èµ°bbq_ruleå¾—åˆ°å·®å¼‚åŒ–è¯„åˆ†

- âŒ **å‘ç°æ–°é—®é¢˜ï¼šHallucinationä»»åŠ¡é›¶æ¢¯åº¦**
  - Step 1ç»„1ï¼š4ä¸ªcandidateså…¨æ˜¯`Reward: 1.000` (Hallucinationä»»åŠ¡)
  - Step 3ç»„1ï¼š4ä¸ªcandidateså…¨æ˜¯`Reward: 1.000` (Hallucinationä»»åŠ¡)
  - å›ç­”å†…å®¹ï¼šå®Œå…¨æ˜¯èƒ¡è¯´å…«é“çš„hallucination
  ```
  "Answer: Good Will Hunting which made film appearance..."
  "Answer: Besides books isn '68 The Sweet Taste..."
  "Answer: Well, Leonard B Burnett won an Academy Award..."
  ```

- ğŸ› **Bug #3ï¼šhalueval_ruleåªæ£€æŸ¥æ ¼å¼ï¼Œä¸æ£€æŸ¥å†…å®¹è´¨é‡**
  ```python
  # æ—§è¯„åˆ†é€»è¾‘ï¼š
  score = 0.5 + 0.3(æœ‰Evidence) + 0.2(é•¿åº¦>30) + 0.1(æœ‰Answer)
  # = 1.1 â†’ clipåˆ°1.0
  ```
  - **é—®é¢˜ï¼š** åªè¦æœ‰`Answer:`ã€`Evidence:`å’Œå¼•å·ï¼Œæ— è®ºå†…å®¹æ˜¯å¦æ­£ç¡®ï¼Œéƒ½æ‹¿1.0
  - **åæœï¼š** 4ä¸ªæ ¼å¼æ­£ç¡®çš„èƒ¡è¯´ â†’ éƒ½æ˜¯1.0 â†’ std=0 â†’ é›¶æ¢¯åº¦

- âœ… **ä¿®å¤æ–¹æ¡ˆï¼ˆCommit e9919ddï¼‰ï¼š**

  **æ·»åŠ Answerå’ŒEvidenceè´¨é‡å·®å¼‚åŒ–è¯„åˆ†ï¼š**

  1. Evidenceè´¨é‡ï¼ˆä¸åªæ˜¯æœ‰æ— ï¼‰ï¼š
     - é•¿åº¦<5è¯ï¼š+0.1ï¼ˆå¤ªçŸ­ï¼‰
     - é•¿åº¦>50è¯ï¼š+0.2ï¼ˆå¤ªå†—é•¿ï¼‰
     - é•¿åº¦5-50è¯ï¼š+0.3ï¼ˆåˆç†ï¼‰

  2. Answerè´¨é‡ï¼ˆä¸åªæ˜¯æœ‰æ— ï¼‰ï¼š
     - é•¿åº¦<3è¯ï¼š-0.2ï¼ˆå¤ªçŸ­ï¼‰
     - é•¿åº¦>30è¯ï¼š-0.1ï¼ˆå¤ªå†—é•¿ï¼‰
     - é•¿åº¦3-30è¯ï¼š+0.2ï¼ˆåˆç†ï¼‰
     - é‡å¤åº¦>50%ï¼š-0.2ï¼ˆé‡å¤ä¸¥é‡ï¼‰

  3. æ•´ä½“é•¿åº¦ï¼š
     - æ€»é•¿<15è¯ï¼š-0.2
     - æ€»é•¿>80è¯ï¼š-0.1

- ğŸ¯ **é¢„æœŸæ•ˆæœï¼š**
  - ä¸åŒcandidateså³ä½¿éƒ½æœ‰æ ¼å¼ï¼Œä¹Ÿä¼šå› é•¿åº¦ã€é‡å¤åº¦ç­‰å·®å¼‚å¾—åˆ°ä¸åŒåˆ†æ•°
  - Hallucinationä»»åŠ¡çš„reward stdåº”>0.2
  - é›¶æ¢¯åº¦ç»„æ¯”ä¾‹åº”<20%

**2025-11-08 (Session 6 - ğŸ”¥ ä½¿ç”¨Ground Truthè¯„ä¼°å†…å®¹è´¨é‡):**
- ğŸ” **è°ƒç ”HaluEvalå®˜æ–¹æ–‡æ¡£**
  - å‘ç°æ•°æ®é›†åº”åŒ…å«knowledge/right_answer/hallucinated_answerå­—æ®µ
  - å½“å‰adapteråŠ è½½äº†è¿™äº›å­—æ®µï¼Œä½†åªç”¨äºæ„å»ºSFT target
  - ä»æœªä¿å­˜åˆ°meta â†’ Judgeæ— æ³•è®¿é—®ï¼
- ğŸ› **å‘ç°æ ¹æœ¬é—®é¢˜ï¼šJudgeæ— æ³•éªŒè¯å†…å®¹æ­£ç¡®æ€§**
  - åªæ£€æŸ¥æ ¼å¼ï¼ˆAnswer/Evidenceå­—æ®µã€é•¿åº¦ï¼‰
  - æ— æ³•åŒºåˆ†"çç¼–ä½†æ ¼å¼æ­£ç¡®"å’Œ"å†…å®¹æ­£ç¡®"
  - å¯¼è‡´é›¶æ¢¯åº¦ç»„ï¼ˆæ‰€æœ‰candidatesçç¼–ä½†éƒ½æ‹¿é«˜åˆ†ï¼‰
- âœ… **å®æ–½CRITICAL FIX (Commit 92c2fc3):**

  **ä¿®å¤1: HaluEvalAdapterä¿å­˜Ground Truthåˆ°meta**
  ```python
  # Line 1226-1232: qaå­é›†
  meta.update({
      "knowledge": know,
      "right_answer": answer,
      "hallucinated_answer": hallucinated_answer,
      ...
  })

  # åŒæ ·ä¿®å¤dialogue, summarization, generalå­é›†
  ```

  **ä¿®å¤2: æ–°å¢_check_content_against_ground_truth()æ–¹æ³•**
  - æ£€æµ‹å£è¯­åŒ–/çç¼–å¼€å¤´ï¼ˆ"yes there", "well maybe", "i think"ï¼‰â†’ -0.3
  - æ£€æµ‹æ¨¡ç³Šæ³›æ³›æè¿°ï¼ˆ"good performance", "in general", "thrills"ï¼‰â†’ -0.2
  - æ£€æŸ¥AnsweråŒ…å«right_answerçš„å…³é”®è¯ï¼ˆé•¿åº¦>3ï¼‰â†’ +0.3
  - æ£€æŸ¥Evidenceå¼•ç”¨knowledgeï¼ˆn-gramåŒ¹é…ï¼‰â†’ +0.2
  - æ£€æŸ¥æ˜¯å¦æ›´æ¥è¿‘hallucinated_answer â†’ -0.2
  - é€‚é…qa/dialogue/summarizationä¸‰ä¸ªå­é›†

  **ä¿®å¤3: é›†æˆåˆ°_evaluate_halueval()**
  - Bonusåˆ†æ•°èŒƒå›´ï¼š[-0.5, +0.5]
  - æœ€ç»ˆåˆ†æ•°ä»clipåˆ°[-1.0, 1.0]

- ğŸ“Š **é¢„æœŸæ•ˆæœï¼š**
  - âœ… çç¼–responsesï¼ˆæ ¼å¼æ­£ç¡®ä½†å†…å®¹é”™ï¼‰ï¼š0.3-0.5åˆ†
  - âœ… æ­£ç¡®responsesï¼ˆæ ¼å¼+å†…å®¹éƒ½å¯¹ï¼‰ï¼š0.8-1.0åˆ†
  - âœ… Reward stdï¼š0.000 â†’ >0.2
  - âœ… é›¶æ¢¯åº¦ç»„ï¼š50% â†’ <20%
- ğŸ’¡ **é‡è¦æ„ä¹‰ï¼š**
  - è¿™æ˜¯åŸºäºHaluEvalå®˜æ–¹æ–‡æ¡£çš„æ ‡å‡†åšæ³•
  - æ¯”å¯å‘å¼è§„åˆ™æ›´å¯é ï¼ˆæœ‰ground truthæ”¯æ’‘ï¼‰
  - ç›´æ¥è§£å†³é›¶æ¢¯åº¦æ ¹å› ï¼ˆæ— æ³•åŒºåˆ†å†…å®¹è´¨é‡ï¼‰

**å¾…éªŒè¯ï¼ˆä¸‹æ¬¡è®­ç»ƒï¼‰ï¼š**
- [ ] å‰10æ­¥çš„å®é™…è§‚å¯Ÿç»“æœï¼ˆå…³æ³¨ç†µæ˜¯å¦ä¸Šå‡ï¼‰
- [ ] æ¨¡å‹æ˜¯å¦å¼€å§‹çœŸæ­£å­¦ä¹ ï¼ˆä¸å†é”æ­»ï¼‰
- [ ] Hallucinationä»»åŠ¡çš„reward stdæ˜¯å¦>0.2
- [ ] é›¶æ¢¯åº¦ç»„æ¯”ä¾‹æ˜¯å¦<20%
- [ ] æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´è¶…å‚ï¼ˆENTROPY_COEF, beta, Temperature, KLç›®æ ‡ï¼‰
- [ ] æœ€ç»ˆè®­ç»ƒæ•ˆæœå’Œæ”¶æ•›æƒ…å†µ

---

**æ–‡æ¡£ç»“æŸã€‚å¦‚æœ‰ç–‘é—®ï¼Œè¯·å‚è€ƒtrainer.pyä¸­çš„è¯¦ç»†æ³¨é‡Šæˆ–é‡æ–°é˜…è¯»æœ¬æ–‡æ¡£çš„ç›¸å…³ç« èŠ‚ã€‚**
