#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ– Entropy å´©æºƒè¯Šæ–­è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¼šå®é™…æ‰§è¡Œè¯Šæ–­ä»£ç ï¼Œè€Œä¸åªæ˜¯æ‰“å°æŒ‡å¯¼ä¿¡æ¯ã€‚

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨è§£æè®­ç»ƒæ—¥å¿—
2. æå–å…³é”®æŒ‡æ ‡ï¼ˆEntropy, Reward, KL, Logitsï¼‰
3. è‡ªåŠ¨åˆ¤æ–­é—®é¢˜æ‰€åœ¨
4. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š

ç”¨æ³•ï¼š
  # è¯Šæ–­è®­ç»ƒæ—¥å¿—
  python scripts/auto_diagnose_entropy.py --log train.log

  # æµ‹è¯• base model entropyï¼ˆéœ€è¦æ¨¡å‹è·¯å¾„ï¼‰
  python scripts/auto_diagnose_entropy.py --test-base-model meta-llama/Llama-3.2-1B-Instruct

  # å®Œæ•´è¯Šæ–­ï¼ˆæ—¥å¿— + æ¨¡å‹ï¼‰
  python scripts/auto_diagnose_entropy.py --log train.log --test-base-model MODEL_PATH
"""

import re
import argparse
import numpy as np
from pathlib import Path
from collections import defaultdict
import sys

print("="*80)
print("ğŸ”¬ è‡ªåŠ¨åŒ– Entropy å´©æºƒè¯Šæ–­")
print("="*80)

# ============================================================================
# æ—¥å¿—è§£æå™¨
# ============================================================================

class LogParser:
    """è§£æè®­ç»ƒæ—¥å¿—ï¼Œæå–å…³é”®æŒ‡æ ‡"""

    def __init__(self, log_path):
        self.log_path = Path(log_path)
        self.steps = defaultdict(dict)

    def parse(self):
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        if not self.log_path.exists():
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {self.log_path}")
            return False

        print(f"\nğŸ“‚ è§£ææ—¥å¿—: {self.log_path}")

        with open(self.log_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå– Logits ä¿¡æ¯
        logits_pattern = r'\[Step (\d+) Logits\].*?Max logit=([\d.]+).*?Gap=([\d.]+).*?Top5=\[([\d.e\-,\s]+)\]'
        for match in re.finditer(logits_pattern, content, re.DOTALL):
            step = int(match.group(1))
            max_logit = float(match.group(2))
            gap = float(match.group(3))
            top5_str = match.group(4)
            top5 = [float(x.strip()) for x in top5_str.split(',')]

            self.steps[step]['max_logit'] = max_logit
            self.steps[step]['gap'] = gap
            self.steps[step]['top5'] = top5
            self.steps[step]['max_prob'] = top5[0] if top5 else None

        # æå– Entropy ä¿¡æ¯
        entropy_pattern = r'\[Fairnessè¯Šæ–­@step(\d+)\].*?Entropy.*?mean.*?=([\d.]+)'
        for match in re.finditer(entropy_pattern, content, re.DOTALL):
            step = int(match.group(1)) - 1  # æ—¥å¿—ä¸­æ˜¯ step+1
            entropy_mean = float(match.group(2))
            self.steps[step]['entropy_mean'] = entropy_mean

        # æå– Reward ä¿¡æ¯
        reward_pattern = r'\[Fairnessè¯Šæ–­@step(\d+)\].*?Reward.*?\(F\).*?=([\d.\-+]+).*?\(H\).*?=([\d.\-+]+)'
        for match in re.finditer(reward_pattern, content, re.DOTALL):
            step = int(match.group(1)) - 1
            reward_f = float(match.group(2))
            reward_h = float(match.group(3))
            self.steps[step]['reward_f'] = reward_f
            self.steps[step]['reward_h'] = reward_h

        # æå– EOS Suppressor ä¿¡æ¯
        eos_pattern = r'Call#(\d+).*?EOS.*?é˜»æ­¢.*?\((\d+)/(\d+)\)'
        eos_blocks = []
        for match in re.finditer(eos_pattern, content):
            call = int(match.group(1))
            blocked = int(match.group(2))
            total = int(match.group(3))
            eos_blocks.append((call, blocked, total))

        if eos_blocks:
            # è®¡ç®—å¹³å‡é˜»æ­¢ç‡
            avg_block_rate = np.mean([b/t for _, b, t in eos_blocks])
            for step in self.steps:
                self.steps[step]['eos_block_rate'] = avg_block_rate

        print(f"âœ… æˆåŠŸè§£æ {len(self.steps)} ä¸ªè®­ç»ƒæ­¥")
        return len(self.steps) > 0

    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.steps:
            return None

        stats = {
            'entropy_mean': [],
            'max_prob': [],
            'gap': [],
            'reward_f': [],
            'reward_h': [],
            'eos_block_rate': []
        }

        for step_data in self.steps.values():
            for key in stats.keys():
                if key in step_data and step_data[key] is not None:
                    stats[key].append(step_data[key])

        # è®¡ç®—ç»Ÿè®¡é‡
        result = {}
        for key, values in stats.items():
            if values:
                result[key] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'median': np.median(values)
                }

        return result

# ============================================================================
# Base Model Entropy æµ‹è¯•å™¨
# ============================================================================

class BaseModelTester:
    """æµ‹è¯• base model çš„ entropy"""

    def __init__(self, model_name):
        self.model_name = model_name

    def test(self):
        """æµ‹è¯• base model entropy"""
        print(f"\nğŸ§ª æµ‹è¯• Base Model: {self.model_name}")

        try:
            import torch
            import torch.nn.functional as F
            from transformers import AutoModelForCausalLM, AutoTokenizer

            print("  åŠ è½½æ¨¡å‹...")
            tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16,
                device_map="auto"
            )
            model.eval()

            # æµ‹è¯• prompt
            prompts = [
                "Context: John has 15 years of experience. Mary has 3 years. Question: Who is more experienced? A) John B) Mary C) Unknown",
                "Answer the following question: What is 2+2?",
                "Complete this sentence: The capital of France is"
            ]

            all_entropies = []
            all_max_probs = []

            for prompt in prompts:
                print(f"\n  æµ‹è¯• prompt: {prompt[:50]}...")

                inputs = tokenizer([prompt], return_tensors="pt").to(model.device)

                with torch.no_grad():
                    outputs = model.generate(
                        **inputs,
                        max_new_tokens=20,
                        do_sample=True,
                        temperature=0.9,
                        return_dict_in_generate=True,
                        output_scores=True
                    )

                # è®¡ç®—æ¯æ­¥çš„ entropy
                entropies = []
                max_probs = []
                for scores in outputs.scores[:10]:  # å‰10ä¸ªtoken
                    probs = F.softmax(scores[0] / 0.9, dim=-1)
                    entropy = -(probs * torch.log(probs + 1e-10)).sum()
                    max_prob = probs.max().item()

                    entropies.append(entropy.item())
                    max_probs.append(max_prob)

                avg_entropy = np.mean(entropies)
                avg_max_prob = np.mean(max_probs)

                all_entropies.extend(entropies)
                all_max_probs.extend(max_probs)

                print(f"    Avg entropy: {avg_entropy:.3f}")
                print(f"    Avg max_prob: {avg_max_prob:.4f}")

            overall_entropy = np.mean(all_entropies)
            overall_max_prob = np.mean(all_max_probs)

            return {
                'mean_entropy': overall_entropy,
                'mean_max_prob': overall_max_prob,
                'all_entropies': all_entropies,
                'all_max_probs': all_max_probs
            }

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            return None

# ============================================================================
# è¯Šæ–­å¼•æ“
# ============================================================================

class DiagnosticEngine:
    """è¯Šæ–­å¼•æ“ï¼Œåˆ†ææ•°æ®å¹¶ç»™å‡ºç»“è®º"""

    def __init__(self):
        self.issues = []
        self.suggestions = []

    def analyze_training_log(self, stats):
        """åˆ†æè®­ç»ƒæ—¥å¿—ç»Ÿè®¡"""
        print("\n" + "="*80)
        print("ğŸ“Š è®­ç»ƒæ—¥å¿—åˆ†æ")
        print("="*80)

        if not stats:
            print("âŒ æ— æœ‰æ•ˆæ•°æ®")
            return

        # åˆ†æ Entropy
        if 'entropy_mean' in stats:
            ent = stats['entropy_mean']
            print(f"\nğŸ” Entropy åˆ†æ:")
            print(f"  å¹³å‡: {ent['mean']:.4f}")
            print(f"  ä¸­ä½æ•°: {ent['median']:.4f}")
            print(f"  èŒƒå›´: [{ent['min']:.4f}, {ent['max']:.4f}]")

            if ent['mean'] < 0.05:
                self.issues.append("ğŸ”´ Entropy ä¸¥é‡å´©æºƒ (< 0.05)")
                self.suggestions.append("ç«‹å³åº”ç”¨ LOW_MEMORY_MODE=True å¿«é€Ÿä¿®å¤")
            elif ent['mean'] < 0.3:
                self.issues.append("ğŸŸ¡ Entropy åä½ (< 0.3)")
                self.suggestions.append("æå‡ ENTROPY_COEF æˆ–æ£€æŸ¥æ¢¯åº¦ç¬¦å·")
            else:
                print("  âœ… Entropy æ­£å¸¸")

        # åˆ†æ Max Prob
        if 'max_prob' in stats:
            mp = stats['max_prob']
            print(f"\nğŸ” Max Probability åˆ†æ:")
            print(f"  å¹³å‡: {mp['mean']:.4f}")
            print(f"  ä¸­ä½æ•°: {mp['median']:.4f}")

            if mp['mean'] > 0.99:
                self.issues.append("ğŸ”´ Max Prob è¿‡é«˜ (> 99%)")
                self.suggestions.append("æ¨¡å‹è¾“å‡ºæåº¦ç¡®å®šï¼Œé…åˆ Entropy å´©æºƒ")
            elif mp['mean'] > 0.90:
                self.issues.append("ğŸŸ¡ Max Prob åé«˜ (> 90%)")

        # åˆ†æ Logit Gap
        if 'gap' in stats:
            gap = stats['gap']
            print(f"\nğŸ” Logit Gap åˆ†æ:")
            print(f"  å¹³å‡: {gap['mean']:.3f}")
            print(f"  ä¸­ä½æ•°: {gap['median']:.3f}")

            if gap['mean'] > 7:
                self.issues.append("ğŸ”´ Logit Gap è¿‡å¤§ (> 7)")
                self.suggestions.append("Logits æåº¦å°–é”ï¼Œå¯èƒ½æ˜¯ base model é—®é¢˜")
            elif gap['mean'] > 5:
                self.issues.append("ğŸŸ¡ Logit Gap åå¤§ (> 5)")

        # åˆ†æ Reward
        if 'reward_f' in stats and 'reward_h' in stats:
            rf = stats['reward_f']
            rh = stats['reward_h']
            print(f"\nğŸ” Reward åˆ†æ:")
            print(f"  Fairness: mean={rf['mean']:.3f}, std={rf['std']:.3f}")
            print(f"  Hallucination: mean={rh['mean']:.3f}, std={rh['std']:.3f}")

            if rf['std'] < 0.1:
                self.issues.append("ğŸ”´ Fairness Reward æ— å˜åŒ– (std < 0.1)")
                self.suggestions.append("Reward ä¿¡å·é€€åŒ–ï¼Œæ£€æŸ¥ judge è¯„ä¼°é€»è¾‘")

            if rh['std'] < 0.1:
                self.issues.append("ğŸ”´ Hallucination Reward æ— å˜åŒ– (std < 0.1)")

        # åˆ†æ EOS Suppressor
        if 'eos_block_rate' in stats:
            eos = stats['eos_block_rate']
            print(f"\nğŸ” EOS Suppressor åˆ†æ:")
            print(f"  å¹³å‡é˜»æ­¢ç‡: {eos['mean']*100:.1f}%")

            if eos['mean'] > 0.8:
                self.issues.append("ğŸ”´ EOS Suppressor è§¦å‘ç‡è¿‡é«˜ (> 80%)")
                self.suggestions.append("MIN_NEW_TOKENS ä¸ SFT target ä¸åŒ¹é…")
            elif eos['mean'] > 0.5:
                self.issues.append("ğŸŸ¡ EOS Suppressor è§¦å‘ç‡åé«˜ (> 50%)")

    def analyze_base_model(self, result):
        """åˆ†æ base model æµ‹è¯•ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ“Š Base Model åˆ†æ")
        print("="*80)

        if not result:
            print("âŒ æ— æµ‹è¯•æ•°æ®")
            return

        mean_ent = result['mean_entropy']
        mean_mp = result['mean_max_prob']

        print(f"\nğŸ” Base Model Entropy:")
        print(f"  å¹³å‡: {mean_ent:.3f}")
        print(f"  Max prob: {mean_mp:.4f}")

        if mean_ent < 0.5:
            self.issues.append("ğŸ”´ Base Model Entropy è¿‡ä½ (< 0.5)")
            self.suggestions.append("Base model æœ¬èº«å°±æœ‰é—®é¢˜ï¼Œè€ƒè™‘æ¢æ¨¡å‹æˆ–é™ä½ KL penalty")
        elif mean_ent < 1.5:
            self.issues.append("ğŸŸ¡ Base Model Entropy åä½ (< 1.5)")
        else:
            print("  âœ… Base Model Entropy æ­£å¸¸")

    def generate_report(self):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“‹ è¯Šæ–­æŠ¥å‘Š")
        print("="*80)

        if not self.issues:
            print("\nâœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")
            return

        print(f"\nå‘ç° {len(self.issues)} ä¸ªé—®é¢˜:")
        for i, issue in enumerate(self.issues, 1):
            print(f"  {i}. {issue}")

        if self.suggestions:
            print(f"\nğŸ’¡ ä¿®å¤å»ºè®® ({len(self.suggestions)} æ¡):")
            for i, suggestion in enumerate(self.suggestions, 1):
                print(f"  {i}. {suggestion}")

        # ç»¼åˆåˆ¤æ–­
        print("\n" + "="*80)
        print("ğŸ¯ ç»¼åˆè¯Šæ–­ç»“è®º")
        print("="*80)

        # æ£€æŸ¥æ˜¯å¦æ˜¯ Entropy æ¢¯åº¦ç¬¦å·é—®é¢˜
        has_entropy_collapse = any("Entropy ä¸¥é‡å´©æºƒ" in issue for issue in self.issues)
        has_high_max_prob = any("Max Prob è¿‡é«˜" in issue for issue in self.issues)
        has_high_eos = any("EOS Suppressor è§¦å‘ç‡è¿‡é«˜" in issue for issue in self.issues)

        if has_entropy_collapse and has_high_max_prob:
            print("\nğŸ”´ é«˜åº¦æ€€ç–‘ï¼šEntropy æ¢¯åº¦ç¬¦å·é”™è¯¯ï¼")
            print("\nåŸå› ï¼š")
            print("  1. Entropy å´©æºƒåˆ° < 0.05")
            print("  2. Max Prob > 99%")
            print("  3. è¿™ç¬¦åˆ'æ¢¯åº¦ç¬¦å·åäº†'çš„ç‰¹å¾")
            print("\nğŸš€ ç«‹å³ä¿®å¤:")
            print("  trainer.py ç¬¬ 286 è¡Œ: LOW_MEMORY_MODE = False â†’ True")
            print("\né¢„æœŸæ•ˆæœ:")
            print("  - Entropy: 0.005 â†’ 0.5-1.5")
            print("  - Max Prob: 99.9% â†’ 60-85%")

        if has_high_eos:
            print("\nğŸŸ¡ å‘ç°ï¼šMIN_NEW_TOKENS ä¸åŒ¹é…")
            print("\nåŸå› ï¼š")
            print("  EOS Suppressor è§¦å‘ç‡ > 80%")
            print("  è¯´æ˜ MIN_NEW_TOKENS è¿œå°äºå®é™…ç”Ÿæˆéœ€æ±‚")
            print("\nğŸš€ ä¿®å¤:")
            print("  trainer.py ç¬¬ 226 è¡Œ: MIN_NEW_TOKENS_TRAIN = 5 â†’ 30")

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def diagnose(log_path=None, base_model=None):
    """
    è¯Šæ–­å‡½æ•°ï¼ˆå¯åœ¨ notebook ä¸­ç›´æ¥è°ƒç”¨ï¼‰

    Args:
        log_path: è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„
        base_model: Base model åç§°/è·¯å¾„
    """
    if not log_path and not base_model:
        print("âŒ è¯·æŒ‡å®š log_path æˆ– base_model")
        print("\nç”¨æ³•:")
        print("  diagnose(log_path='train.log')")
        print("  diagnose(base_model='meta-llama/Llama-3.2-1B-Instruct')")
        print("  diagnose(log_path='train.log', base_model='MODEL_NAME')")
        return None

    engine = DiagnosticEngine()

    # åˆ†æè®­ç»ƒæ—¥å¿—
    if log_path:
        parser = LogParser(log_path)
        if parser.parse():
            stats = parser.get_stats()
            engine.analyze_training_log(stats)

    # æµ‹è¯• base model
    if base_model:
        tester = BaseModelTester(base_model)
        result = tester.test()
        if result:
            engine.analyze_base_model(result)

    # ç”ŸæˆæŠ¥å‘Š
    engine.generate_report()

    print("\n" + "="*80)
    print("âœ… è¯Šæ–­å®Œæˆ")
    print("="*80)

    return engine

def main():
    """å‘½ä»¤è¡Œå…¥å£ï¼ˆæ£€æµ‹ notebook ç¯å¢ƒï¼‰"""
    # æ£€æµ‹æ˜¯å¦åœ¨ notebook ç¯å¢ƒ
    try:
        get_ipython()
        in_notebook = True
    except NameError:
        in_notebook = False

    if in_notebook:
        print("ğŸ”” æ£€æµ‹åˆ° Jupyter notebook ç¯å¢ƒ")
        print("\nåœ¨ notebook ä¸­ä½¿ç”¨å‡½æ•°å¼æ¥å£ï¼š")
        print("  from auto_diagnose_entropy import diagnose")
        print("  diagnose(log_path='train.log')")
        print("  diagnose(base_model='MODEL_NAME')")
        return

    # å‘½ä»¤è¡Œæ¨¡å¼
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ– Entropy å´©æºƒè¯Šæ–­')
    parser.add_argument('--log', type=str, help='è®­ç»ƒæ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test-base-model', type=str, help='Base model åç§°/è·¯å¾„')

    args = parser.parse_args()

    diagnose(log_path=args.log, base_model=args.test_base_model)

if __name__ == "__main__":
    main()
