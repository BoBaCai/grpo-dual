# å¦‚ä½•è¿è¡Œ GRPO Trainer + LLM Judge

## ğŸ“ é¡¹ç›®ç»“æ„

```
grpo-dual/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ grpo/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trainer.py          # âœ… ä¸»è®­ç»ƒå™¨ï¼ˆå·²ä¿®å¤å¯¼å…¥è·¯å¾„ï¼‰
â”‚   â””â”€â”€ judges/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ llm_judge_prompts_v2.py  # âœ… LLM Judge V2ï¼ˆè‡ªé€‚åº”è¯„åˆ†ï¼‰
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bbq/                    # BBQ å…¬å¹³æ€§æ•°æ®é›†
â”‚   â””â”€â”€ halueval/               # HaluEval å¹»è§‰æ£€æµ‹æ•°æ®é›†
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ llm_judge_usage_example.ipynb
â”‚   â””â”€â”€ QUICK_START.md
â””â”€â”€ requirements.txt
```

---

## ğŸš€ æ–¹å¼ 1ï¼šæœ¬åœ°è¿è¡Œï¼ˆæ¨èï¼‰

### **1.1 ç¯å¢ƒå‡†å¤‡**

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/BoBaCai/grpo-dual.git
cd grpo-dual

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### **1.2 è®¾ç½® API Key**

```bash
# è®¾ç½® OpenAI API Keyï¼ˆå¿…é¡»ï¼‰
export OPENAI_API_KEY="sk-your-api-key-here"

# å¯é€‰ï¼šAnthropic API Keyï¼ˆå¦‚æœéœ€è¦Claude Judgeï¼‰
export ANTHROPIC_API_KEY="your-anthropic-key"
```

### **1.3 è¿è¡Œè®­ç»ƒ**

**æ–¹å¼ Aï¼šç›´æ¥è¿è¡Œ trainer.py**

```bash
cd grpo-dual/src/grpo
python trainer.py
```

**æ–¹å¼ Bï¼šä½¿ç”¨ Python æ¨¡å—è¿è¡Œ**

```bash
cd grpo-dual
python -m src.grpo.trainer
```

**æ–¹å¼ Cï¼šåœ¨ Python è„šæœ¬ä¸­å¯¼å…¥**

```python
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path("/path/to/grpo-dual")
sys.path.insert(0, str(project_root / "src" / "grpo"))

# è®¾ç½® API Key
os.environ["OPENAI_API_KEY"] = "sk-your-key"

# å¯¼å…¥å¹¶è¿è¡Œ
from trainer import GRPOConfig, GRPOTrainer

config = GRPOConfig()
trainer = GRPOTrainer(config)
trainer.train()
```

---

## ğŸŒ æ–¹å¼ 2ï¼šä» GitHub ç›´æ¥è°ƒç”¨ï¼ˆé«˜çº§ï¼‰

### **2.1 åŠ¨æ€ä¸‹è½½å¹¶å¯¼å…¥ï¼ˆå®éªŒæ€§ï¼‰**

å¦‚æœæ‚¨æƒ³ç›´æ¥ä» GitHub æ‹‰å–æœ€æ–°ä»£ç ï¼š

```python
import os
import sys
import urllib.request
from pathlib import Path

# ä¸‹è½½ llm_judge_prompts_v2.py
github_raw = "https://raw.githubusercontent.com/BoBaCai/grpo-dual/main/src/judges/llm_judge_prompts_v2.py"
local_path = Path.cwd() / "llm_judge_prompts_v2.py"

# ä¸‹è½½æ–‡ä»¶
urllib.request.urlretrieve(github_raw, local_path)

# æ·»åŠ åˆ°è·¯å¾„
sys.path.insert(0, str(Path.cwd()))

# ç°åœ¨å¯ä»¥å¯¼å…¥
from llm_judge_prompts_v2 import get_adaptive_bbq_prompt, get_adaptive_halueval_prompt
```

### **2.2 ä½¿ç”¨ Git å­æ¨¡å—ï¼ˆæ¨èç»™åä½œé¡¹ç›®ï¼‰**

å¦‚æœæ‚¨åœ¨å¦ä¸€ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨ grpo-dualï¼š

```bash
# åœ¨æ‚¨çš„é¡¹ç›®ä¸­æ·»åŠ å­æ¨¡å—
git submodule add https://github.com/BoBaCai/grpo-dual.git external/grpo-dual
git submodule update --init --recursive

# åœ¨ä»£ç ä¸­ä½¿ç”¨
import sys
sys.path.insert(0, "external/grpo-dual/src/judges")
from llm_judge_prompts_v2 import get_adaptive_bbq_prompt
```

---

## ğŸ“Š æ–¹å¼ 3ï¼šåœ¨ Jupyter Notebook ä¸­ä½¿ç”¨ï¼ˆæœ€ç®€å•ï¼‰

### **3.1 ä¸Šä¼ æ–‡ä»¶åˆ° workspace**

æŠŠ `llm_judge_prompts_v2.py` ä¸Šä¼ åˆ°ä½ çš„ Jupyter workspace æ–‡ä»¶å¤¹

### **3.2 å‡†å¤‡ç¯å¢ƒï¼ˆCell 1ï¼‰**

```python
import os
import sys
from pathlib import Path

# âœ… ç›´æ¥ä»å½“å‰ç›®å½•å¯¼å…¥
sys.path.insert(0, str(Path.cwd()))

# è®¾ç½® API Key
os.environ["OPENAI_API_KEY"] = "sk-your-key"
```

### **3.3 å¯¼å…¥å¹¶ä½¿ç”¨ï¼ˆCell 2ï¼‰**

```python
from llm_judge_prompts_v2 import get_adaptive_bbq_prompt, get_adaptive_halueval_prompt
from openai import OpenAI
import json

client = OpenAI()

def judge_score(judge_prompt):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.0,
        response_format={"type": "json_object"},
        messages=[{"role": "user", "content": judge_prompt}],
        max_tokens=200
    )
    return json.loads(response.choices[0].message.content)

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆè¯¦è§ notebooks/QUICK_START.mdï¼‰
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### **Trainer é…ç½®ï¼ˆtrainer.pyï¼‰**

```python
class GRPOConfig:
    # LLM Judge é…ç½®
    LLM_JUDGE_VERSION = "v2"  # âœ… ä½¿ç”¨è‡ªé€‚åº” prompt

    # Judge Providerï¼ˆåªç”¨ OpenAIï¼‰
    JUDGE_PROVIDERS = [
        {"name": "openai", "model": "gpt-4o-mini"}
    ]

    # è®­ç»ƒé…ç½®
    BATCH_SIZE = 8
    K_CANDIDATES = 4  # æ¯ä¸ª prompt ç”Ÿæˆ 4 ä¸ªå€™é€‰
    NUM_EPOCHS = 3

    # æ•°æ®é›†é…ç½®
    NUM_SAMPLES_FAIRNESS = 100
    NUM_SAMPLES_HALLUCINATION = 100
```

### **Judge é…ç½®ï¼ˆllm_judge_prompts_v2.pyï¼‰**

```python
# æ–‡ä»¶æœ«å°¾çš„é…ç½®
JUDGE_MODE = "llm_adaptive"
LLM_JUDGE_MODEL = "gpt-4o-mini"
LLM_JUDGE_TEMPERATURE = 0.0
LLM_JUDGE_MAX_TOKENS = 200
```

---

## ğŸ”§ è·¯å¾„ä¿®å¤è¯´æ˜ï¼ˆå·²å®Œæˆï¼‰

**é—®é¢˜**ï¼šä¹‹å‰ trainer.py ä¸­çš„å¯¼å…¥ä¼šå¤±è´¥

**ä¿®å¤**ï¼ˆå·²è‡ªåŠ¨ä¿®å¤ï¼‰ï¼š
```python
# trainer.py:2042-2053
# åŠ¨æ€æ·»åŠ judgesç›®å½•åˆ°è·¯å¾„
import sys
from pathlib import Path
judges_dir = Path(__file__).parent.parent / "judges"
if str(judges_dir) not in sys.path:
    sys.path.insert(0, str(judges_dir))

# ç°åœ¨å¯ä»¥æ­£å¸¸å¯¼å…¥
from llm_judge_prompts_v2 import get_adaptive_bbq_prompt, get_adaptive_halueval_prompt
```

**å·¥ä½œåŸç†**ï¼š
- `Path(__file__)` â†’ `/path/to/grpo-dual/src/grpo/trainer.py`
- `.parent.parent` â†’ `/path/to/grpo-dual/src/`
- `/ "judges"` â†’ `/path/to/grpo-dual/src/judges/`
- æ·»åŠ åˆ° `sys.path`ï¼ŒPython å°±èƒ½æ‰¾åˆ° `llm_judge_prompts_v2.py`

---

## ğŸ“¦ éœ€è¦æä¾›çš„æ–‡ä»¶ï¼ˆå¦‚æœç»™åˆ«äººï¼‰

### **æœ€å°å·¥ä½œé›†**

å¦‚æœæ‚¨æƒ³ç»™åˆ«äººä½¿ç”¨ LLM Judge V2ï¼Œåªéœ€æä¾›ï¼š

1. **`llm_judge_prompts_v2.py`** - Judge æ ¸å¿ƒé€»è¾‘
2. **ä½¿ç”¨è¯´æ˜** - `notebooks/QUICK_START.md` æˆ–æœ¬æ–‡æ¡£

### **å®Œæ•´é¡¹ç›®**

å¦‚æœè¦è¿è¡Œå®Œæ•´è®­ç»ƒï¼š

1. **ä»£ç æ–‡ä»¶**ï¼š
   - `src/grpo/trainer.py`
   - `src/judges/llm_judge_prompts_v2.py`
   - `src/models/lora_setup.py`
   - `src/evals/metrics.py`

2. **æ•°æ®é›†**ï¼š
   - `data/bbq/*.jsonl`
   - `data/halueval/*.json`

3. **é…ç½®æ–‡ä»¶**ï¼š
   - `requirements.txt`
   - `configs/*.yaml`ï¼ˆå¦‚æœæœ‰ï¼‰

4. **æ–‡æ¡£**ï¼š
   - `README.md`
   - `HANDOFF.md`
   - `notebooks/QUICK_START.md`

---

## ğŸŒ GitHub é›†æˆå»ºè®®

### **æ–¹å¼ Aï¼šå‘å¸ƒ Python åŒ…ï¼ˆPyPIï¼‰**

å¦‚æœæ‚¨æƒ³è®©åˆ«äººé€šè¿‡ `pip install` ä½¿ç”¨ï¼š

```bash
# 1. åˆ›å»º setup.py
cat > setup.py <<EOF
from setuptools import setup, find_packages

setup(
    name="grpo-dual",
    version="0.1.0",
    packages=find_packages(where="src"),
    package_dir={"": "src"},
    install_requires=[
        "openai>=2.3.0",
        "anthropic>=0.69.0",
        "torch>=2.0.0",
        # ... å…¶ä»–ä¾èµ–
    ],
)
EOF

# 2. å®‰è£…
pip install -e .

# 3. ä½¿ç”¨
from judges.llm_judge_prompts_v2 import get_adaptive_bbq_prompt
```

### **æ–¹å¼ Bï¼šç›´æ¥ä» GitHub å®‰è£…**

```bash
pip install git+https://github.com/BoBaCai/grpo-dual.git
```

### **æ–¹å¼ Cï¼šGitHub Release + å•æ–‡ä»¶ä¸‹è½½**

åˆ›å»º GitHub Releaseï¼Œé™„å¸¦ï¼š
- `llm_judge_prompts_v2.py`ï¼ˆå•æ–‡ä»¶ç‰ˆæœ¬ï¼‰
- `QUICK_START.md`

ç”¨æˆ·å¯ç›´æ¥ä¸‹è½½å•ä¸ªæ–‡ä»¶ä½¿ç”¨ã€‚

---

## ğŸ› å¸¸è§é—®é¢˜

### **Q1: ModuleNotFoundError: No module named 'llm_judge_prompts_v2'**

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# ç¡®ä¿æ·»åŠ æ­£ç¡®çš„è·¯å¾„
import sys
from pathlib import Path
sys.path.insert(0, str(Path("grpo-dual/src/judges")))
```

### **Q2: å¦‚ä½•éªŒè¯å¯¼å…¥æˆåŠŸï¼Ÿ**

```python
# æµ‹è¯•å¯¼å…¥
try:
    from llm_judge_prompts_v2 import get_adaptive_bbq_prompt
    print("âœ… å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
```

### **Q3: ä» GitHub æ‹‰å–æ—¶è·¯å¾„æ€ä¹ˆåŠï¼Ÿ**

```python
# åŠ¨æ€ä¸‹è½½åæ·»åŠ è·¯å¾„
import urllib.request
from pathlib import Path

# ä¸‹è½½åˆ°å½“å‰ç›®å½•
url = "https://raw.githubusercontent.com/BoBaCai/grpo-dual/main/src/judges/llm_judge_prompts_v2.py"
Path("judges").mkdir(exist_ok=True)
urllib.request.urlretrieve(url, "judges/llm_judge_prompts_v2.py")

# æ·»åŠ è·¯å¾„
import sys
sys.path.insert(0, str(Path.cwd()))

# å¯¼å…¥
from judges.llm_judge_prompts_v2 import get_adaptive_bbq_prompt
```

---

## ğŸ“ è”ç³»ä¸æ”¯æŒ

- **GitHub Issues**: https://github.com/BoBaCai/grpo-dual/issues
- **æ–‡æ¡£**: è§ `notebooks/` ç›®å½•

ç¥æ‚¨ä½¿ç”¨é¡ºåˆ©ï¼ğŸš€
