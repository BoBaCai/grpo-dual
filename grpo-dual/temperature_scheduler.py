#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Temperature Scheduler for GRPO Multi-Objective Training

åŸºäº DeepSeek-R1 å’Œ EDT çš„æœ€ä½³å®è·µï¼š
- Stage-wise é™æ¸©ï¼ˆé«˜æ¢ç´¢ â†’ æ”¶æ•› â†’ éƒ¨ç½²å¯¹é½ï¼‰
- Per-task å·®å¼‚åŒ–æ¸©åº¦ï¼ˆFairness vs Hallucinationï¼‰
- è½»é‡è‡ªé€‚åº”ï¼ˆç†µ + æˆªæ–­ç‡é©±åŠ¨ï¼‰

å‚è€ƒæ–‡çŒ®ï¼š
- DeepSeek-R1: Stage 1 T=1.0, Stage 2 T=0.7
- EDT: ç†µé©±åŠ¨åŠ¨æ€æ¸©åº¦
- DAPO: å¤šç›®æ ‡ RL é•¿åº¦æ§åˆ¶
"""

from typing import Dict, Tuple, Optional
from dataclasses import dataclass
import math


@dataclass
class TemperatureConfig:
    """æ¸©åº¦è°ƒåº¦é…ç½®"""

    # å…¨å±€èŒƒå›´
    T_min: float = 0.6
    T_max: float = 1.3
    delta_T: float = 0.05  # è‡ªé€‚åº”æ­¥é•¿

    # ç†µç›®æ ‡
    entropy_target_low: float = 3.0
    entropy_target_high: float = 4.0

    # æˆªæ–­ç‡é˜ˆå€¼ï¼ˆper-stageï¼‰
    trunc_threshold_stage1: float = 0.40
    trunc_threshold_stage2: float = 0.15
    trunc_threshold_stage3: float = 0.10

    # Stage åˆ’åˆ†ï¼ˆæ¯”ä¾‹ï¼‰
    stage1_end: float = 0.30  # 0-30%: æ¢ç´¢æœŸ
    stage2_end: float = 0.80  # 30-80%: æ”¶æ•›æœŸ
    # 80-100%: éƒ¨ç½²å¯¹é½æœŸ

    # Per-task åŸºç¡€æ¸©åº¦ï¼ˆStage 1ï¼‰
    fairness_T_init: float = 1.10
    hallucination_T_init: float = 0.95

    # Per-task æ¸©åº¦èŒƒå›´ï¼ˆStage 1ï¼‰
    fairness_T_range_s1: Tuple[float, float] = (1.0, 1.25)
    hallucination_T_range_s1: Tuple[float, float] = (0.8, 1.10)

    # Per-task æ¸©åº¦ç›®æ ‡ï¼ˆStage 2 ç»ˆç‚¹ï¼‰
    fairness_T_end_s2: float = 0.90
    hallucination_T_end_s2: float = 0.80

    # Per-task æ¸©åº¦èŒƒå›´ï¼ˆStage 2ï¼‰
    fairness_T_range_s2: Tuple[float, float] = (0.8, 1.10)
    hallucination_T_range_s2: Tuple[float, float] = (0.7, 0.95)

    # Per-task æ¸©åº¦èŒƒå›´ï¼ˆStage 3ï¼‰
    fairness_T_range_s3: Tuple[float, float] = (0.75, 0.90)
    hallucination_T_range_s3: Tuple[float, float] = (0.70, 0.80)

    # è‡ªé€‚åº”æ¨¡å¼ï¼ˆper-stageï¼‰
    stage1_adapt_mode: str = "truncation_only"  # "truncation_only", "entropy_only", "both", "none"
    stage2_adapt_mode: str = "both"
    stage3_adapt_mode: str = "truncation_only"

    # ç»Ÿè®¡çª—å£
    window_steps: int = 50  # æ¯ N æ­¥æ›´æ–°ä¸€æ¬¡æ¸©åº¦


class TemperatureScheduler:
    """
    ä¸‰é˜¶æ®µæ¸©åº¦è°ƒåº¦å™¨ï¼Œæ”¯æŒ per-task å’Œè½»é‡è‡ªé€‚åº”

    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    scheduler = TemperatureScheduler(total_steps=500)

    # æ¯ä¸ªè®­ç»ƒæ­¥
    temps = scheduler.get_temperature(
        step=current_step,
        fairness_entropy=2.5,
        fairness_trunc_rate=0.3,
        hallucination_entropy=3.2,
        hallucination_trunc_rate=0.2
    )

    T_fairness = temps['fairness']
    T_hallucination = temps['hallucination']
    ```
    """

    def __init__(self, total_steps: int, config: Optional[TemperatureConfig] = None):
        self.total_steps = total_steps
        self.config = config or TemperatureConfig()

        # å½“å‰æ¸©åº¦ï¼ˆper-taskï¼‰
        self.current_T = {
            'fairness': self.config.fairness_T_init,
            'hallucination': self.config.hallucination_T_init
        }

        # ç»Ÿè®¡ç¼“å†²ï¼ˆç”¨äºæ»‘åŠ¨å¹³å‡ï¼‰
        self.entropy_buffer = {'fairness': [], 'hallucination': []}
        self.trunc_buffer = {'fairness': [], 'hallucination': []}

        # å†å²è®°å½•ï¼ˆç”¨äºåˆ†æå’Œå¯è§†åŒ–ï¼‰
        self.history = {
            'step': [],
            'stage': [],
            'fairness_T': [],
            'hallucination_T': [],
            'fairness_entropy': [],
            'hallucination_entropy': [],
            'fairness_trunc': [],
            'hallucination_trunc': [],
            'fairness_adapt_reason': [],
            'hallucination_adapt_reason': []
        }

    def get_current_stage(self, step: int) -> int:
        """ç¡®å®šå½“å‰æ‰€å¤„çš„ stage (1, 2, 3)"""
        progress = step / self.total_steps

        if progress <= self.config.stage1_end:
            return 1
        elif progress <= self.config.stage2_end:
            return 2
        else:
            return 3

    def get_stage_progress(self, step: int) -> float:
        """è·å–å½“å‰ stage å†…çš„è¿›åº¦ [0.0, 1.0]"""
        progress = step / self.total_steps
        stage = self.get_current_stage(step)

        if stage == 1:
            return progress / self.config.stage1_end
        elif stage == 2:
            stage_start = self.config.stage1_end
            stage_length = self.config.stage2_end - self.config.stage1_end
            return (progress - stage_start) / stage_length
        else:  # stage == 3
            stage_start = self.config.stage2_end
            stage_length = 1.0 - self.config.stage2_end
            return (progress - stage_start) / stage_length

    def get_base_temperature(self, step: int, task: str) -> float:
        """
        è·å–åŸºç¡€æ¸©åº¦ï¼ˆstage-wise scheduleï¼Œä¸è€ƒè™‘è‡ªé€‚åº”ï¼‰

        Args:
            step: å½“å‰æ­¥æ•°
            task: 'fairness' or 'hallucination'

        Returns:
            åŸºç¡€æ¸©åº¦å€¼
        """
        stage = self.get_current_stage(step)
        stage_progress = self.get_stage_progress(step)

        if task == 'fairness':
            if stage == 1:
                return self.config.fairness_T_init
            elif stage == 2:
                # çº¿æ€§é€€ç«ä» Stage 1 æœ«å°¾åˆ° Stage 2 ç›®æ ‡
                T_start = self.config.fairness_T_init
                T_end = self.config.fairness_T_end_s2
                return T_start + (T_end - T_start) * stage_progress
            else:  # stage == 3
                # ä¿æŒåœ¨ Stage 2 çš„ç»ˆç‚¹å€¼
                return self.config.fairness_T_end_s2

        else:  # hallucination
            if stage == 1:
                return self.config.hallucination_T_init
            elif stage == 2:
                T_start = self.config.hallucination_T_init
                T_end = self.config.hallucination_T_end_s2
                return T_start + (T_end - T_start) * stage_progress
            else:  # stage == 3
                return self.config.hallucination_T_end_s2

    def get_temperature_range(self, step: int, task: str) -> Tuple[float, float]:
        """è·å–å½“å‰ stage ä¸‹è¯¥ä»»åŠ¡çš„æ¸©åº¦èŒƒå›´"""
        stage = self.get_current_stage(step)

        if task == 'fairness':
            if stage == 1:
                return self.config.fairness_T_range_s1
            elif stage == 2:
                return self.config.fairness_T_range_s2
            else:
                return self.config.fairness_T_range_s3
        else:  # hallucination
            if stage == 1:
                return self.config.hallucination_T_range_s1
            elif stage == 2:
                return self.config.hallucination_T_range_s2
            else:
                return self.config.hallucination_T_range_s3

    def get_adapt_mode(self, step: int) -> str:
        """è·å–å½“å‰ stage çš„è‡ªé€‚åº”æ¨¡å¼"""
        stage = self.get_current_stage(step)

        if stage == 1:
            return self.config.stage1_adapt_mode
        elif stage == 2:
            return self.config.stage2_adapt_mode
        else:
            return self.config.stage3_adapt_mode

    def get_truncation_threshold(self, step: int) -> float:
        """è·å–å½“å‰ stage çš„æˆªæ–­ç‡é˜ˆå€¼"""
        stage = self.get_current_stage(step)

        if stage == 1:
            return self.config.trunc_threshold_stage1
        elif stage == 2:
            return self.config.trunc_threshold_stage2
        else:
            return self.config.trunc_threshold_stage3

    def update_temperature_adaptive(
        self,
        task: str,
        entropy: float,
        trunc_rate: float,
        step: int
    ) -> Tuple[float, str]:
        """
        è‡ªé€‚åº”è°ƒæ•´æ¸©åº¦ï¼ˆç†µ + æˆªæ–­ç‡é©±åŠ¨ï¼‰

        Args:
            task: 'fairness' or 'hallucination'
            entropy: å½“å‰æ‰¹æ¬¡çš„å¹³å‡ç†µ
            trunc_rate: å½“å‰æ‰¹æ¬¡çš„æˆªæ–­ç‡
            step: å½“å‰æ­¥æ•°

        Returns:
            (æ–°æ¸©åº¦, è°ƒæ•´åŸå› )
        """
        current_T = self.current_T[task]
        T_min, T_max = self.get_temperature_range(step, task)
        adapt_mode = self.get_adapt_mode(step)
        trunc_threshold = self.get_truncation_threshold(step)

        # å¦‚æœä¸å¯ç”¨è‡ªé€‚åº”ï¼Œç›´æ¥è¿”å›åŸºç¡€æ¸©åº¦
        if adapt_mode == "none":
            base_T = self.get_base_temperature(step, task)
            return np.clip(base_T, T_min, T_max), "none"

        # åˆå§‹åŒ–è°ƒæ•´
        new_T = current_T
        reason = "stable"

        # æ£€æŸ¥æˆªæ–­ç‡
        if adapt_mode in ["truncation_only", "both"]:
            if trunc_rate > trunc_threshold:
                new_T = max(new_T - self.config.delta_T, T_min)
                reason = f"trunc_high({trunc_rate:.2f}>{trunc_threshold:.2f})"

        # æ£€æŸ¥ç†µ
        if adapt_mode in ["entropy_only", "both"] and reason == "stable":
            if entropy < self.config.entropy_target_low:
                new_T = min(new_T + self.config.delta_T, T_max)
                reason = f"entropy_low({entropy:.2f}<{self.config.entropy_target_low})"
            elif entropy > self.config.entropy_target_high:
                new_T = max(new_T - self.config.delta_T, T_min)
                reason = f"entropy_high({entropy:.2f}>{self.config.entropy_target_high})"

        # Clip åˆ°å…è®¸èŒƒå›´
        new_T = max(T_min, min(T_max, new_T))

        return new_T, reason

    def get_temperature(
        self,
        step: int,
        fairness_entropy: Optional[float] = None,
        fairness_trunc_rate: Optional[float] = None,
        hallucination_entropy: Optional[float] = None,
        hallucination_trunc_rate: Optional[float] = None
    ) -> Dict[str, float]:
        """
        è·å–å½“å‰æ­¥çš„æ¸©åº¦ï¼ˆä¸»æ¥å£ï¼‰

        Args:
            step: å½“å‰è®­ç»ƒæ­¥æ•°
            fairness_entropy: Fairness ä»»åŠ¡çš„å¹³å‡ç†µï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªé€‚åº”ï¼‰
            fairness_trunc_rate: Fairness ä»»åŠ¡çš„æˆªæ–­ç‡ï¼ˆå¯é€‰ï¼‰
            hallucination_entropy: Hallucination ä»»åŠ¡çš„å¹³å‡ç†µï¼ˆå¯é€‰ï¼‰
            hallucination_trunc_rate: Hallucination ä»»åŠ¡çš„æˆªæ–­ç‡ï¼ˆå¯é€‰ï¼‰

        Returns:
            {'fairness': T_f, 'hallucination': T_h, 'stage': stage}
        """
        stage = self.get_current_stage(step)

        # åªåœ¨çª—å£è¾¹ç•Œæ›´æ–°æ¸©åº¦ï¼ˆå‡å°‘æŠ–åŠ¨ï¼‰
        should_update = (step % self.config.window_steps == 0) or (step == 0)

        if should_update:
            # æ›´æ–° Fairness æ¸©åº¦
            if fairness_entropy is not None and fairness_trunc_rate is not None:
                new_T_f, reason_f = self.update_temperature_adaptive(
                    'fairness', fairness_entropy, fairness_trunc_rate, step
                )
                self.current_T['fairness'] = new_T_f
            else:
                # å¦‚æœæ²¡æœ‰æä¾›æŒ‡æ ‡ï¼Œä½¿ç”¨åŸºç¡€æ¸©åº¦
                self.current_T['fairness'] = self.get_base_temperature(step, 'fairness')
                reason_f = "no_metrics"

            # æ›´æ–° Hallucination æ¸©åº¦
            if hallucination_entropy is not None and hallucination_trunc_rate is not None:
                new_T_h, reason_h = self.update_temperature_adaptive(
                    'hallucination', hallucination_entropy, hallucination_trunc_rate, step
                )
                self.current_T['hallucination'] = new_T_h
            else:
                self.current_T['hallucination'] = self.get_base_temperature(step, 'hallucination')
                reason_h = "no_metrics"

            # è®°å½•å†å²
            self.history['step'].append(step)
            self.history['stage'].append(stage)
            self.history['fairness_T'].append(self.current_T['fairness'])
            self.history['hallucination_T'].append(self.current_T['hallucination'])
            self.history['fairness_entropy'].append(fairness_entropy or 0.0)
            self.history['hallucination_entropy'].append(hallucination_entropy or 0.0)
            self.history['fairness_trunc'].append(fairness_trunc_rate or 0.0)
            self.history['hallucination_trunc'].append(hallucination_trunc_rate or 0.0)
            self.history['fairness_adapt_reason'].append(reason_f)
            self.history['hallucination_adapt_reason'].append(reason_h)

            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            if step % (self.config.window_steps * 5) == 0:  # æ¯ 5 ä¸ªçª—å£æ‰“å°ä¸€æ¬¡
                f_ent_str = f"{fairness_entropy:.2f}" if fairness_entropy is not None else "N/A"
                f_trunc_str = f"{fairness_trunc_rate:.2%}" if fairness_trunc_rate is not None else "N/A"
                h_ent_str = f"{hallucination_entropy:.2f}" if hallucination_entropy is not None else "N/A"
                h_trunc_str = f"{hallucination_trunc_rate:.2%}" if hallucination_trunc_rate is not None else "N/A"

                print(f"\nğŸŒ¡ï¸ [Step {step}] Temperature Update (Stage {stage}):")
                print(f"  Fairness:      T={self.current_T['fairness']:.3f} | "
                      f"Entropy={f_ent_str} | Trunc={f_trunc_str} | Reason: {reason_f}")
                print(f"  Hallucination: T={self.current_T['hallucination']:.3f} | "
                      f"Entropy={h_ent_str} | Trunc={h_trunc_str} | Reason: {reason_h}")

        return {
            'fairness': self.current_T['fairness'],
            'hallucination': self.current_T['hallucination'],
            'stage': stage
        }

    def get_kl_coefficient(self, step: int) -> float:
        """
        è·å–å½“å‰æ­¥çš„ KL ç³»æ•°ï¼ˆé…åˆæ¸©åº¦è°ƒåº¦ï¼‰

        å‚è€ƒ DeepSeek-R1: Stage 1 å° KL (0.001) â†’ Stage 2-3 é€æ­¥å¢å¤§
        """
        stage = self.get_current_stage(step)
        stage_progress = self.get_stage_progress(step)

        if stage == 1:
            return 0.003  # ä½çº¦æŸï¼Œé«˜æ¢ç´¢
        elif stage == 2:
            # ä» 0.003 çº¿æ€§å¢é•¿åˆ° 0.01
            return 0.003 + (0.01 - 0.003) * stage_progress
        else:  # stage == 3
            # ä» 0.01 å¢é•¿åˆ° 0.02
            return 0.01 + (0.02 - 0.01) * stage_progress

    def get_max_new_tokens(self, step: int) -> int:
        """
        è·å–å½“å‰æ­¥çš„ max_new_tokensï¼ˆé…åˆæ¸©åº¦è°ƒåº¦ï¼‰

        Stage 1-2 å‰æœŸ: 256ï¼ˆç»™è¶³ç©ºé—´ï¼‰
        Stage 2 åæœŸ: é™åˆ° 192
        Stage 3: ä¿æŒ 192
        """
        stage = self.get_current_stage(step)
        stage_progress = self.get_stage_progress(step)

        if stage == 1:
            return 256
        elif stage == 2:
            if stage_progress < 0.5:
                return 256
            else:
                # çº¿æ€§ä» 256 é™åˆ° 192
                return int(256 - (256 - 192) * (stage_progress - 0.5) / 0.5)
        else:  # stage == 3
            return 192

    def get_truncation_penalty(self, step: int) -> float:
        """
        è·å–æˆªæ–­æƒ©ç½šç³»æ•°ï¼ˆä¹˜åˆ° reward ä¸Šï¼‰

        Stage 1: è½»å¾® (0.7)
        Stage 2: ä¸­ç­‰ (0.5)
        Stage 3: ä¸¥é‡ (0.3)
        """
        stage = self.get_current_stage(step)

        if stage == 1:
            return 0.7
        elif stage == 2:
            return 0.5
        else:
            return 0.3

    def get_length_penalty_lambda(self, step: int) -> float:
        """
        è·å–é•¿åº¦æ­£åˆ™åŒ–ç³»æ•°

        Stage 1: å¾ˆå° (0.01)
        Stage 2: ä¸­ç­‰ (0.03)
        Stage 3: è¾ƒå¤§ (0.05)
        """
        stage = self.get_current_stage(step)

        if stage == 1:
            return 0.01
        elif stage == 2:
            return 0.03
        else:
            return 0.05

    def save_history(self, path: str):
        """ä¿å­˜æ¸©åº¦è°ƒæ•´å†å²åˆ° CSV"""
        import csv

        if not self.history['step']:
            print("âš ï¸ No history to save")
            return

        with open(path, 'w', newline='') as f:
            writer = csv.writer(f)
            # å†™å…¥è¡¨å¤´
            headers = list(self.history.keys())
            writer.writerow(headers)

            # å†™å…¥æ•°æ®è¡Œ
            num_rows = len(self.history['step'])
            for i in range(num_rows):
                row = [self.history[key][i] for key in headers]
                writer.writerow(row)

        print(f"âœ… Temperature history saved to {path}")

    def plot_history(self, save_path: str = "temperature_history.png"):
        """ç»˜åˆ¶æ¸©åº¦è°ƒæ•´å†å²"""
        try:
            import matplotlib.pyplot as plt

            if not self.history['step']:
                print("âš ï¸ No history to plot")
                return

            # ç›´æ¥ä½¿ç”¨ history å­—å…¸
            df = self.history

            fig, axes = plt.subplots(3, 2, figsize=(14, 10))
            fig.suptitle('Temperature Scheduler History', fontsize=16)

            # æ¸©åº¦æ›²çº¿
            axes[0, 0].plot(df['step'], df['fairness_T'], label='Fairness', color='blue')
            axes[0, 0].plot(df['step'], df['hallucination_T'], label='Hallucination', color='red')
            axes[0, 0].set_ylabel('Temperature')
            axes[0, 0].set_title('Temperature Over Time')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)

            # ç†µæ›²çº¿
            axes[0, 1].plot(df['step'], df['fairness_entropy'], label='Fairness', color='blue')
            axes[0, 1].plot(df['step'], df['hallucination_entropy'], label='Hallucination', color='red')
            axes[0, 1].axhline(y=self.config.entropy_target_low, color='green', linestyle='--', alpha=0.5)
            axes[0, 1].axhline(y=self.config.entropy_target_high, color='orange', linestyle='--', alpha=0.5)
            axes[0, 1].set_ylabel('Entropy')
            axes[0, 1].set_title('Entropy Over Time')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

            # æˆªæ–­ç‡æ›²çº¿
            axes[1, 0].plot(df['step'], df['fairness_trunc'], label='Fairness', color='blue')
            axes[1, 0].plot(df['step'], df['hallucination_trunc'], label='Hallucination', color='red')
            axes[1, 0].set_ylabel('Truncation Rate')
            axes[1, 0].set_title('Truncation Rate Over Time')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)

            # Stage åˆ†å¸ƒ
            axes[1, 1].scatter(df['step'], df['stage'], alpha=0.5)
            axes[1, 1].set_ylabel('Stage')
            axes[1, 1].set_title('Training Stage')
            axes[1, 1].set_yticks([1, 2, 3])
            axes[1, 1].grid(True, alpha=0.3)

            # æ¸©åº¦ vs ç†µï¼ˆFairnessï¼‰
            axes[2, 0].scatter(df['fairness_entropy'], df['fairness_T'],
                              c=df['step'], cmap='viridis', alpha=0.6)
            axes[2, 0].set_xlabel('Entropy')
            axes[2, 0].set_ylabel('Temperature')
            axes[2, 0].set_title('Fairness: T vs Entropy (color=step)')
            axes[2, 0].grid(True, alpha=0.3)

            # æ¸©åº¦ vs æˆªæ–­ç‡ï¼ˆHallucinationï¼‰
            axes[2, 1].scatter(df['hallucination_trunc'], df['hallucination_T'],
                              c=df['step'], cmap='viridis', alpha=0.6)
            axes[2, 1].set_xlabel('Truncation Rate')
            axes[2, 1].set_ylabel('Temperature')
            axes[2, 1].set_title('Hallucination: T vs Truncation (color=step)')
            axes[2, 1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(save_path, dpi=150)
            print(f"âœ… Temperature plot saved to {save_path}")

        except ImportError:
            print("âš ï¸ matplotlib not available, skip plotting")


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = TemperatureScheduler(total_steps=500)

    print("=" * 80)
    print("Temperature Scheduler Demo")
    print("=" * 80)

    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for step in [0, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500]:
        # æ¨¡æ‹ŸæŒ‡æ ‡ï¼ˆéšæœºï¼‰
        fairness_entropy = np.random.uniform(2.0, 4.5)
        fairness_trunc = np.random.uniform(0.1, 0.5)
        halu_entropy = np.random.uniform(2.5, 4.0)
        halu_trunc = np.random.uniform(0.05, 0.3)

        temps = scheduler.get_temperature(
            step=step,
            fairness_entropy=fairness_entropy,
            fairness_trunc_rate=fairness_trunc,
            hallucination_entropy=halu_entropy,
            hallucination_trunc_rate=halu_trunc
        )

        if step % 100 == 0:
            print(f"\nStep {step} (Stage {temps['stage']}):")
            print(f"  KL coef: {scheduler.get_kl_coefficient(step):.4f}")
            print(f"  Max tokens: {scheduler.get_max_new_tokens(step)}")
            print(f"  Trunc penalty: {scheduler.get_truncation_penalty(step):.2f}")

    # ä¿å­˜å†å²
    scheduler.save_history("/tmp/temperature_history.csv")
    scheduler.plot_history("/tmp/temperature_history.png")

    print("\n" + "=" * 80)
    print("âœ… Demoå®Œæˆï¼")
    print("=" * 80)
