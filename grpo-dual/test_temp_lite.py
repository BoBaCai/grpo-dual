#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è½»é‡ç‰ˆTemperature vs Entropyæµ‹è¯• (Notebookå‹å¥½)

å¯ä»¥ç›´æ¥åœ¨notebook cellä¸­å¤åˆ¶ç²˜è´´è¿è¡Œ
"""

import sys
from pathlib import Path
import torch
import numpy as np
from collections import defaultdict

# ============================================================================
# è‡ªåŠ¨æŸ¥æ‰¾grpo-dualç›®å½•
# ============================================================================
print("="*80)
print("ğŸŒ¡ï¸ Temperature vs Entropy è½»é‡æµ‹è¯•")
print("="*80)

# æœç´¢å¯èƒ½çš„grpo-dualä½ç½®
possible_paths = [
    Path.cwd() / 'grpo-dual',
    Path.cwd(),
    Path.cwd().parent / 'grpo-dual',
    Path('/home/user/grpo-dual/grpo-dual'),
]

grpo_dual_dir = None
for p in possible_paths:
    if (p / 'src' / 'grpo' / 'trainer.py').exists():
        grpo_dual_dir = p
        print(f"âœ“ æ‰¾åˆ°grpo-dualç›®å½•: {p}\n")
        break

if grpo_dual_dir is None:
    print("âŒ æ— æ³•æ‰¾åˆ°grpo-dualç›®å½•ï¼")
    sys.exit(1)

# æ·»åŠ åˆ°Pythonè·¯å¾„
src_dir = grpo_dual_dir / 'src'
sys.path.insert(0, str(src_dir))

from grpo.trainer import Config
from transformers import AutoTokenizer, AutoModelForCausalLM

# ============================================================================
# é…ç½®
# ============================================================================
config = Config()
device = "cuda" if torch.cuda.is_available() else "cpu"

# åªæµ‹è¯•å…³é”®æ¸©åº¦ç‚¹
TEMPS_TO_TEST = [0.7, 1.0, 1.2, 1.5]

# åªç”¨3ä¸ªpromptså¿«é€Ÿæµ‹è¯•
TEST_PROMPTS = [
    "Question: What is the capital of France?",
    "Explain machine learning in simple terms.",
    "If a train travels 120 km in 2 hours, what is its average speed?",
]

# ============================================================================
# åŠ è½½æ¨¡å‹
# ============================================================================
print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {config.BASE_MODEL}")
print(f"è®¾å¤‡: {device}\n")

try:
    tokenizer = AutoTokenizer.from_pretrained(config.BASE_MODEL)
    model = AutoModelForCausalLM.from_pretrained(
        config.BASE_MODEL,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32,
        device_map="auto" if device == "cuda" else None,
    )
    if device == "cpu":
        model = model.to(device)
    model.eval()
    print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ\n")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# ============================================================================
# æ ¸å¿ƒå‡½æ•°
# ============================================================================
def compute_entropy(logits: torch.Tensor, temperature: float) -> float:
    """è®¡ç®—ç»™å®šæ¸©åº¦ä¸‹çš„token-levelç†µ"""
    scaled_logits = logits / temperature
    probs = torch.softmax(scaled_logits, dim=-1)
    log_probs = torch.log(probs + 1e-10)
    entropy = -(probs * log_probs).sum().item()
    return entropy

def test_temperature(prompt: str, temperature: float, max_tokens: int = 20) -> dict:
    """æµ‹è¯•å•ä¸ªæ¸©åº¦"""
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    entropies = []

    with torch.no_grad():
        for _ in range(max_tokens):
            outputs = model(**inputs)
            next_token_logits = outputs.logits[0, -1, :]

            entropy = compute_entropy(next_token_logits, temperature)
            entropies.append(entropy)

            probs = torch.softmax(next_token_logits / temperature, dim=-1)
            next_token = torch.multinomial(probs, num_samples=1)

            if next_token.item() == tokenizer.eos_token_id:
                break

            inputs.input_ids = torch.cat([inputs.input_ids, next_token.unsqueeze(0)], dim=1)
            if 'attention_mask' in inputs:
                inputs.attention_mask = torch.cat([
                    inputs.attention_mask,
                    torch.ones((1, 1), dtype=torch.long, device=device)
                ], dim=1)

    return {
        'mean_entropy': np.mean(entropies),
        'tokens': len(entropies),
    }

# ============================================================================
# ä¸»æµ‹è¯•
# ============================================================================
print("="*80)
print("ğŸ§ª å¼€å§‹æµ‹è¯•")
print("="*80)

results = defaultdict(list)

for temp in TEMPS_TO_TEST:
    print(f"\nğŸŒ¡ï¸ Temperature = {temp}")

    for i, prompt in enumerate(TEST_PROMPTS, 1):
        result = test_temperature(prompt, temp, max_tokens=20)
        results[temp].append(result['mean_entropy'])
        print(f"  Prompt {i}: ç†µ={result['mean_entropy']:.3f}, tokens={result['tokens']}")

# ============================================================================
# ç»Ÿè®¡åˆ†æ
# ============================================================================
print("\n" + "="*80)
print("ğŸ“Š ç»Ÿè®¡æ±‡æ€»")
print("="*80)

print("\n  Temp  | å¹³å‡ç†µ | æ ‡å‡†å·® | ç†µå¢é•¿ç‡ | çŠ¶æ€")
print("  ------|--------|--------|----------|----------")

temps = sorted(results.keys())
mean_entropies = []

for i, temp in enumerate(temps):
    entropies = results[temp]
    mean_ent = np.mean(entropies)
    std_ent = np.std(entropies)
    mean_entropies.append(mean_ent)

    if i > 0:
        prev_mean = mean_entropies[i-1]
        growth_rate = (mean_ent - prev_mean) / prev_mean * 100
        growth_str = f"+{growth_rate:.1f}%"
    else:
        growth_str = "-"

    marker = " â† å½“å‰" if temp == 1.2 else ""
    print(f"  {temp:.1f}  | {mean_ent:.3f}  | {std_ent:.3f}  | {growth_str:8s} | æ­£å¸¸{marker}")

# ============================================================================
# å»ºè®®
# ============================================================================
print("\n" + "="*80)
print("ğŸ’¡ ç»“è®º")
print("="*80)

current_temp = 1.2
current_entropy = mean_entropies[temps.index(current_temp)]

print(f"\nå½“å‰T={current_temp}çš„å¹³å‡ç†µ: {current_entropy:.3f} nats")
print(f"ï¼ˆç­‰ä»·äº {current_entropy / np.log(2):.3f} bitsï¼‰")

# æ£€æŸ¥ç†µå¢é•¿è¶‹åŠ¿
if len(mean_entropies) >= 3:
    growth_rates = [
        (mean_entropies[i] - mean_entropies[i-1]) / mean_entropies[i-1]
        for i in range(1, len(mean_entropies))
    ]
    avg_growth = np.mean(growth_rates)

    print(f"\nå¹³å‡ç†µå¢é•¿ç‡: {avg_growth*100:.1f}%")

    if avg_growth > 0.3:
        print("âš ï¸ ç†µå¢é•¿è¾ƒå¿«ï¼Œå¯èƒ½æ¥è¿‘spikeåŒºåŸŸ")
    else:
        print("âœ“ ç†µå¢é•¿å¹³ç¨³ï¼Œæ¸©åº¦è®¾ç½®åˆç†")

print(f"\nâœ“ T=1.2åœ¨æµ‹è¯•èŒƒå›´å†…è¡¨ç°æ­£å¸¸")
print(f"  ç†µå€¼é€‚ä¸­ï¼ˆ{current_entropy:.3f}ï¼‰ï¼Œæ”¯æŒå½“å‰é…ç½®")

print("\n" + "="*80)
print("ğŸ” æµ‹è¯•å®Œæˆï¼")
print("="*80)
